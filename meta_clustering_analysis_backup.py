import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.decomposition import PCA
import io
import base64

# Matplotlib font ayarlarÄ± - emoji uyarÄ±larÄ±nÄ± azaltmak iÃ§in
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

@st.cache_data
def perform_direct_meta_clustering(X, n_clusters=5, random_state=42, init_method='k-means++', n_init=10, max_iter=300):
    """
    DoÄŸrudan meta kÃ¼meleme (K-means) uygular - geliÅŸmiÅŸ parametre kontrolÃ¼
    """
    try:
        # K-means kÃ¼meleme - daha fazla parametre kontrolÃ¼
        kmeans = KMeans(
            n_clusters=n_clusters, 
            random_state=random_state,
            init=init_method,
            n_init=n_init,
            max_iter=max_iter,
            algorithm='lloyd'  # Lloyd algoritmasÄ± daha deterministik
        )
        labels = kmeans.fit_predict(X)
        
        # Metrikleri hesapla
        silhouette = silhouette_score(X, labels)
        
        return {
            'labels': labels,
            'silhouette_score': silhouette,
            'cluster_centers': kmeans.cluster_centers_,
            'inertia': kmeans.inertia_,
            'n_iter': kmeans.n_iter_
        }
    except Exception as e:
        st.error(f"Meta kÃ¼meleme hatasÄ±: {str(e)}")
        return None

@st.cache_data
def perform_alternative_clustering(X, algorithm='spectral', n_clusters=5, random_state=42):
    """
    SOM'dan farklÄ± sonuÃ§lar iÃ§in alternatif kÃ¼meleme algoritmalarÄ±
    """
    try:
        if algorithm == 'spectral':
            from sklearn.cluster import SpectralClustering
            clustering = SpectralClustering(
                n_clusters=n_clusters, 
                random_state=random_state,
                affinity='rbf',
                gamma=1.0
            )
        elif algorithm == 'agglomerative':
            from sklearn.cluster import AgglomerativeClustering
            clustering = AgglomerativeClustering(
                n_clusters=n_clusters,
                linkage='ward'
            )
        elif algorithm == 'dbscan':
            from sklearn.cluster import DBSCAN
            # DBSCAN iÃ§in eps deÄŸerini otomatik hesapla
            from sklearn.neighbors import NearestNeighbors
            neighbors = NearestNeighbors(n_neighbors=4)
            neighbors_fit = neighbors.fit(X)
            distances, indices = neighbors_fit.kneighbors(X)
            distances = np.sort(distances, axis=0)
            distances = distances[:,1]
            eps = np.percentile(distances, 95)
            
            clustering = DBSCAN(eps=eps, min_samples=5)
        else:  # VarsayÄ±lan: K-means random init
            clustering = KMeans(
                n_clusters=n_clusters,
                random_state=random_state,
                init='random',  # Random initialization
                n_init=20,
                algorithm='lloyd'
            )
        
        labels = clustering.fit_predict(X)
        
        # DBSCAN iÃ§in gÃ¼rÃ¼ltÃ¼ noktalarÄ±nÄ± iÅŸle
        if algorithm == 'dbscan':
            # -1 (gÃ¼rÃ¼ltÃ¼) etiketlerini 0'a Ã§evir
            unique_labels = len(set(labels)) - (1 if -1 in labels else 0)
            labels = np.where(labels == -1, unique_labels, labels)
            n_clusters = unique_labels + 1
        
        # SilÃ¼et skoru hesapla (en az 2 kÃ¼me varsa)
        if len(set(labels)) > 1:
            silhouette = silhouette_score(X, labels)
        else:
            silhouette = 0.0
        
        return {
            'labels': labels,
            'silhouette_score': silhouette,
            'algorithm': algorithm,
            'n_clusters_found': len(set(labels))
        }
        
    except Exception as e:
        st.error(f"Alternatif kÃ¼meleme hatasÄ± ({algorithm}): {str(e)}")
        return None

@st.cache_data
def visualize_meta_clusters(X, labels, n_clusters, cluster_centers):
    """
    Meta kÃ¼meleme sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirir - geliÅŸmiÅŸ hata kontrolÃ¼ ile
    """
    try:
        # Veri kontrolÃ¼ - NaN deÄŸerleri temizle
        if np.any(np.isnan(X)) or np.any(np.isinf(X)):
            st.warning("Veri setinde NaN veya sonsuz deÄŸerler tespit edildi, temizleniyor...")
            # NaN ve sonsuz deÄŸerleri temizle
            finite_mask = np.all(np.isfinite(X), axis=1)
            X_clean = X[finite_mask]
            labels_clean = labels[finite_mask]
            
            if len(X_clean) == 0:
                st.error("TÃ¼m veriler geÃ§ersiz, gÃ¶rselleÅŸtirme yapÄ±lamÄ±yor!")
                return None
        else:
            X_clean = X
            labels_clean = labels
        
        # KÃ¼me sayÄ±sÄ±nÄ± gerÃ§ek veriden hesapla
        unique_labels = len(np.unique(labels_clean))
        actual_n_clusters = min(n_clusters, unique_labels)
        
        # PCA ile 2 boyuta indir - Ã¶zel kontrol
        if X_clean.shape[1] == 1:
            # Tek Ã¶zellik varsa Ã¶zel iÅŸlem
            X_2d = np.column_stack([X_clean.flatten(), np.zeros(len(X_clean))])
            explained_variance = [1.0, 0.0]
        elif X_clean.shape[0] < 2:
            st.error("GÃ¶rselleÅŸtirme iÃ§in en az 2 veri noktasÄ± gerekli!")
            return None
        else:
            # Standart PCA
            pca = PCA(n_components=min(2, X_clean.shape[1]))
            X_2d = pca.fit_transform(X_clean)
            explained_variance = pca.explained_variance_ratio_
            
            # Tek boyutlu sonuÃ§ varsa ikinci boyutu sÄ±fÄ±r ekle
            if X_2d.shape[1] == 1:
                X_2d = np.column_stack([X_2d, np.zeros(len(X_2d))])
                explained_variance = np.append(explained_variance, 0.0)
        
        # GÃ¶rselleÅŸtirme
        fig = plt.figure(figsize=(15, 10))
        
        # 1. KÃ¼meleme gÃ¶rselleÅŸtirmesi
        plt.subplot(221)
        scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], 
                            c=labels_clean,
                            cmap='viridis', alpha=0.6)
        plt.title('Meta KÃ¼meleme SonuÃ§larÄ± (PCA)')
        plt.xlabel(f'PC1 ({explained_variance[0]:.2%})')
        plt.ylabel(f'PC2 ({explained_variance[1]:.2%})')
        plt.colorbar(scatter, label='KÃ¼me')
        
        # 2. KÃ¼me boyutlarÄ±
        plt.subplot(222)
        cluster_sizes = pd.Series(labels_clean).value_counts().sort_index()
        if len(cluster_sizes) > 0:
            bars = plt.bar(cluster_sizes.index, cluster_sizes.values, 
                          color=plt.cm.viridis(np.linspace(0, 1, len(cluster_sizes))))
            plt.title('KÃ¼me BoyutlarÄ±')
            plt.xlabel('KÃ¼me')
            plt.ylabel('Veri SayÄ±sÄ±')
            # Ã‡ubuklarÄ±n Ã¼zerine deÄŸerleri yazdÄ±r
            for bar in bars:
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                        f'{int(height)}', ha='center', va='bottom')
        else:
            plt.text(0.5, 0.5, 'KÃ¼me bulunamadÄ±', ha='center', va='center')
            plt.title('KÃ¼me BoyutlarÄ±')
        
        # 3. SilÃ¼et analizi
        plt.subplot(223)
        try:
            from sklearn.metrics import silhouette_samples
            if len(np.unique(labels_clean)) > 1:
                silhouette_vals = silhouette_samples(X_clean, labels_clean)
                y_lower = 10
                
                for i in range(actual_n_clusters):
                    cluster_silhouette_vals = silhouette_vals[labels_clean == i]
                    if len(cluster_silhouette_vals) > 0:
                        cluster_silhouette_vals.sort()
                        
                        size_cluster_i = len(cluster_silhouette_vals)
                        y_upper = y_lower + size_cluster_i
                        
                        color = plt.cm.viridis(float(i) / actual_n_clusters)
                        plt.fill_betweenx(np.arange(y_lower, y_upper),
                                         0, cluster_silhouette_vals,
                                         facecolor=color, edgecolor=color, alpha=0.7)
                        
                        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
                        y_lower = y_upper + 10
                
                plt.title('SilÃ¼et Analizi')
                plt.xlabel('SilÃ¼et Skoru')
                plt.ylabel('KÃ¼me')
            else:
                plt.text(0.5, 0.5, 'SilÃ¼et analizi iÃ§in\nen az 2 kÃ¼me gerekli', 
                        ha='center', va='center')
                plt.title('SilÃ¼et Analizi')
        except Exception as e:
            plt.text(0.5, 0.5, f'SilÃ¼et analizi hatasÄ±:\n{str(e)[:50]}...', 
                    ha='center', va='center')
            plt.title('SilÃ¼et Analizi')
        
        # 4. KÃ¼me merkezleri (sadece K-means iÃ§in)
        plt.subplot(224)
        if cluster_centers is not None and len(cluster_centers) > 0:
            try:
                # KÃ¼me merkezlerini de PCA ile dÃ¶nÃ¼ÅŸtÃ¼r
                if X_clean.shape[1] == 1:
                    centers_2d = np.column_stack([cluster_centers.flatten(), np.zeros(len(cluster_centers))])
                else:
                    if 'pca' in locals():
                        centers_2d = pca.transform(cluster_centers)
                        if centers_2d.shape[1] == 1:
                            centers_2d = np.column_stack([centers_2d, np.zeros(len(centers_2d))])
                    else:
                        centers_2d = cluster_centers[:, :2] if cluster_centers.shape[1] >= 2 else np.column_stack([cluster_centers, np.zeros(len(cluster_centers))])
                
                plt.scatter(centers_2d[:, 0], centers_2d[:, 1], 
                           c='red', marker='x', s=200, linewidths=3)
                plt.title('KÃ¼me Merkezleri (PCA)')
                plt.xlabel('PC1')
                plt.ylabel('PC2')
            except Exception as e:
                plt.text(0.5, 0.5, f'Merkez gÃ¶rselleÅŸtirme hatasÄ±:\n{str(e)[:50]}...', 
                        ha='center', va='center')
                plt.title('KÃ¼me Merkezleri')
        else:
            plt.text(0.5, 0.5, 'Bu algoritma iÃ§in\nkÃ¼me merkezleri mevcut deÄŸil\n(Spectral, Agglomerative, DBSCAN)', 
                    ha='center', va='center')
            plt.title('KÃ¼me Merkezleri')
        
        plt.tight_layout()
        
        return fig
    except Exception as e:
        st.error(f"GÃ¶rselleÅŸtirme hatasÄ±: {str(e)}")
        import traceback
        st.error(f"Detay: {traceback.format_exc()}")
        return None

@st.cache_data
def compare_clustering_approaches(X, som_neurons, meta_labels):
    """
    SOM ve meta kÃ¼meleme sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
    """
    try:
        if som_neurons is None or meta_labels is None:
            st.error("KarÅŸÄ±laÅŸtÄ±rma iÃ§in hem SOM hem de meta kÃ¼meleme sonuÃ§larÄ± gerekli!")
            return None
            
        # SOM etiketlerini al
        som_labels = st.session_state.som_labels
        
        # Veri boyutlarÄ±nÄ± kontrol et
        if len(som_labels) != len(meta_labels):
            st.error(f"Veri boyutlarÄ± uyumsuz: SOM ({len(som_labels)}) vs Meta ({len(meta_labels)})")
            return None
            
        # Adjusted Rand Index hesapla
        ari = adjusted_rand_score(som_labels, meta_labels)
        
        # SilÃ¼et skorlarÄ±nÄ± hesapla
        som_silhouette = silhouette_score(X, som_labels)
        meta_silhouette = silhouette_score(X, meta_labels)
        
        return {
            'adjusted_rand_index': ari,
            'som_silhouette': som_silhouette,
            'meta_silhouette': meta_silhouette
        }
    except Exception as e:
        st.error(f"KarÅŸÄ±laÅŸtÄ±rma hatasÄ±: {str(e)}")
        return None

@st.cache_data
def perform_neuron_based_meta_clustering(neuron_weights, n_clusters=5, random_state=42):
    """
    SOM nÃ¶ronlarÄ±nÄ± kÃ¼meleyip loglarÄ± bu kÃ¼melere atar
    """
    try:
        # NÃ¶ron aÄŸÄ±rlÄ±klarÄ±nÄ± kÃ¼meleme
        from sklearn.cluster import KMeans
        kmeans = KMeans(
            n_clusters=n_clusters, 
            random_state=random_state,
            init='k-means++',
            n_init=10,
            algorithm='lloyd'
        )
        neuron_labels = kmeans.fit_predict(neuron_weights)
        
        # SilÃ¼et skoru hesapla
        if len(set(neuron_labels)) > 1:
            neuron_silhouette = silhouette_score(neuron_weights, neuron_labels)
        else:
            neuron_silhouette = 0.0
        
        return {
            'neuron_labels': neuron_labels,
            'neuron_silhouette': neuron_silhouette,
            'cluster_centers': kmeans.cluster_centers_,
            'inertia': kmeans.inertia_,
            'n_iter': kmeans.n_iter_
        }
    except Exception as e:
        st.error(f"NÃ¶ron bazÄ±nda meta kÃ¼meleme hatasÄ±: {str(e)}")
        return None

@st.cache_data  
def map_logs_to_neuron_clusters(bmu_coordinates, neuron_labels, grid_size):
    """
    LoglarÄ± nÃ¶ron kÃ¼melerine eÅŸler
    """
    try:
        # BMU koordinatlarÄ±nÄ± nÃ¶ron indekslerine Ã§evir
        bmu_indices = bmu_coordinates[:, 0] * grid_size + bmu_coordinates[:, 1]
        
        # Log etiketlerini nÃ¶ron etiketlerine eÅŸle
        log_labels = np.array([neuron_labels[int(idx)] for idx in bmu_indices])
        
        return log_labels
    except Exception as e:
        st.error(f"Log-nÃ¶ron eÅŸleme hatasÄ±: {str(e)}")
        return None

def show_meta_clustering_analysis():
    # CSS stilleri - sadece bu sayfa iÃ§in
    st.markdown("""
    <style>
        .meta-control-card {
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 16px;
            padding: 1.5rem;
            margin-bottom: 1rem;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .meta-control-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 4px;
            height: 100%;
            background: #1e40af;
        }
        
        .meta-control-card h4 {
            margin: 0;
            color: #0f172a !important;
            font-weight: 600;
            font-family: 'Inter', sans-serif;
        }
        
        .meta-hero {
            background: linear-gradient(135deg, #ffffff 0%, #f8fafc 100%);
            border: 1px solid #e2e8f0;
            padding: 3rem 2rem;
            border-radius: 20px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .meta-hero::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, #1e40af, #3b82f6);
        }
        
        .meta-hero h1 {
            color: #0f172a !important;
            margin: 0;
            font-size: 2.2rem;
            font-weight: 700;
            letter-spacing: -0.025em;
            font-family: 'Inter', sans-serif;
        }
        
        .meta-hero p {
            color: #475569;
            margin: 0.5rem 0 0 0;
            font-size: 1.1rem;
        }
        
        .status-card {
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
            padding: 1rem;
            text-align: center;
            transition: all 0.3s ease;
        }

        .status-card:hover {
            border-color: #cbd5e1;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
        }
    </style>
    """, unsafe_allow_html=True)
    
    # Session state baÅŸlangÄ±Ã§ deÄŸerleri - her Ã§aÄŸrÄ±da kontrol et
    defaults = {
        "meta_clustering_done": False,
        "direct_meta_labels": None,
        "direct_meta_metrics": None,
        "last_n_clusters": 5,
        "direct_meta_cluster_centers": None,
        "comparison_type": "DoÄŸrudan K-means vs SOM",
        "meta_results_visible": False,
        "comparison_results": None
    }
    
    for key, default in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default

    # Hero section
    st.markdown("""
        <div class="meta-hero">
            <h1>Meta KÃ¼meleme Analizi</h1>
            <p>K-means algoritmasÄ±yla doÄŸrudan kÃ¼meleme ve SOM karÅŸÄ±laÅŸtÄ±rmasÄ±</p>
        </div>
    """, unsafe_allow_html=True)

    # Ana kontrol paneli
    st.markdown("### Kontrol Paneli")
    
    control_col1, control_col2 = st.columns([1, 1])
    
    with control_col1:
        st.markdown("""
            <div class="meta-control-card">
                <h4>KÃ¼meleme AyarlarÄ±</h4>
            </div>
        """, unsafe_allow_html=True)
        
        # Algoritma seÃ§imi
        algorithm_choice = st.selectbox(
            "KÃ¼meleme AlgoritmasÄ±",
            options=['K-means (Standart)', 'K-means (Random Init)', 'Spectral Clustering', 'Agglomerative', 'DBSCAN'],
            help="FarklÄ± algoritmalar farklÄ± kÃ¼meleme sonuÃ§larÄ± verebilir"
        )
        
        # KÃ¼meleme tipi seÃ§imi
        clustering_type = st.radio(
            "KÃ¼meleme Tipi",
            options=["Log BazÄ±nda", "NÃ¶ron BazÄ±nda"],
            help="Log bazÄ±nda: Ham log verilerini kÃ¼meler | NÃ¶ron bazÄ±nda: SOM nÃ¶ronlarÄ±nÄ± kÃ¼meler, loglarÄ± eÅŸler"
        )
        
        if clustering_type == "NÃ¶ron BazÄ±nda":
            st.info("ğŸ§  **NÃ¶ron BazÄ±nda KÃ¼meleme**: SOM nÃ¶ronlarÄ± kÃ¼melenir, sonra loglar nÃ¶ron kÃ¼melerine atanÄ±r. Bu yÃ¶ntem SOM'un Ã¶ÄŸrendiÄŸi yapÄ±yÄ± kullanÄ±r.")
        else:
            st.info("ğŸ“Š **Log BazÄ±nda KÃ¼meleme**: Ham log verileri doÄŸrudan kÃ¼melenir. SOM'dan baÄŸÄ±msÄ±z kÃ¼meleme yapar.")
        
        # KÃ¼me sayÄ±sÄ± seÃ§imi
        n_clusters = st.slider(
            "KÃ¼me SayÄ±sÄ±",
            min_value=2,
            max_value=25,
            value=st.session_state.last_n_clusters,
            help="Meta kÃ¼meleme iÃ§in kullanÄ±lacak kÃ¼me sayÄ±sÄ± (DBSCAN iÃ§in etkisiz)",
            disabled=(algorithm_choice == 'DBSCAN'),
            key="meta_n_clusters_slider"
        )
        
        # GeliÅŸmiÅŸ K-means parametreleri
        if algorithm_choice.startswith('K-means'):
            with st.expander("GeliÅŸmiÅŸ Parametreler"):
                random_state = st.number_input(
                    "Random State", 
                    min_value=1, 
                    max_value=9999, 
                    value=42,
                    help="FarklÄ± deÄŸerler farklÄ± baÅŸlangÄ±Ã§ noktalarÄ± verir"
                )
                
                n_init = st.slider(
                    "BaÅŸlangÄ±Ã§ Deneme SayÄ±sÄ±",
                    min_value=1,
                    max_value=50,
                    value=10,
                    help="Daha fazla deneme daha iyi sonuÃ§ verebilir"
                )
                
                max_iter = st.slider(
                    "Maksimum Ä°terasyon",
                    min_value=100,
                    max_value=1000,
                    value=300,
                    help="YakÄ±nsama iÃ§in maksimum iterasyon sayÄ±sÄ±"
                )
        else:
            random_state = 42
            n_init = 10
            max_iter = 300
        
        # Slider deÄŸeri deÄŸiÅŸtiÄŸinde session state'i gÃ¼ncelle
        if n_clusters != st.session_state.last_n_clusters:
            st.session_state.last_n_clusters = n_clusters

        # Meta kÃ¼meleme butonu
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¯ Standart Meta KÃ¼meleme", use_container_width=True, key="meta_apply_standard"):
                with st.spinner(f"{clustering_type} meta kÃ¼meleme uygulanÄ±yor..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    if clustering_type == "NÃ¶ron BazÄ±nda":
                        # NÃ¶ron bazÄ±nda kÃ¼meleme
                        status_text.text("SOM nÃ¶ronlarÄ± kÃ¼meleniyor...")
                        progress_bar.progress(25)
                        
                        # SOM nÃ¶ron aÄŸÄ±rlÄ±klarÄ±nÄ± al
                        if hasattr(st.session_state, 'som') and st.session_state.som is not None:
                            som_weights = st.session_state.som.get_weights()
                            # Reshape: (grid_x, grid_y, features) -> (grid_x*grid_y, features)
                            neuron_weights = som_weights.reshape(-1, som_weights.shape[-1])
                            
                            # NÃ¶ron kÃ¼meleme
                            neuron_results = perform_neuron_based_meta_clustering(
                                neuron_weights, n_clusters, random_state
                            )
                            
                            if neuron_results:
                                progress_bar.progress(60)
                                status_text.text("Loglar nÃ¶ron kÃ¼melerine eÅŸleniyor...")
                                
                                # BMU koordinatlarÄ±nÄ± al
                                bmu_coords = np.array([st.session_state.som.winner(x) for x in st.session_state.X])
                                grid_size = int(np.sqrt(len(neuron_weights)))
                                
                                # LoglarÄ± nÃ¶ron kÃ¼melerine eÅŸle
                                log_labels = map_logs_to_neuron_clusters(
                                    bmu_coords, neuron_results['neuron_labels'], grid_size
                                )
                                
                                if log_labels is not None:
                                    progress_bar.progress(85)
                                    status_text.text("SonuÃ§lar kaydediliyor...")
                                    
                                    # Log silÃ¼et skorunu hesapla
                                    if len(set(log_labels)) > 1:
                                        log_silhouette = silhouette_score(st.session_state.X, log_labels)
                                    else:
                                        log_silhouette = 0.0
                                    
                                    st.session_state.direct_meta_labels = log_labels
                                    st.session_state.direct_meta_metrics = {
                                        'silhouette_score': log_silhouette,
                                        'neuron_silhouette': neuron_results['neuron_silhouette'],
                                        'algorithm': f"NÃ¶ron BazÄ±nda {algorithm_choice}",
                                        'clustering_type': 'neuron_based'
                                    }
                                    st.session_state.direct_meta_cluster_centers = neuron_results['cluster_centers']
                                    st.session_state.meta_clustering_done = True
                                    st.session_state.last_n_clusters = n_clusters
                                    st.session_state.meta_results_visible = True
                                    
                                    progress_bar.progress(100)
                                    status_text.success("NÃ¶ron bazÄ±nda kÃ¼meleme tamamlandÄ±!")
                                    st.balloons()
                                    st.rerun()
                                else:
                                    st.error("Log-nÃ¶ron eÅŸleme baÅŸarÄ±sÄ±z!")
                            else:
                                st.error("NÃ¶ron kÃ¼meleme baÅŸarÄ±sÄ±z!")
                        else:
                            st.error("SOM modeli bulunamadÄ±! Ã–nce SOM analizi yapÄ±n.")
                    
                    else:
                        # Log bazÄ±nda kÃ¼meleme (mevcut iÅŸlem)
                        status_text.text("Loglar kÃ¼meleniyor...")
                        progress_bar.progress(25)
                        
                        if algorithm_choice == 'K-means (Standart)':
                            results = perform_direct_meta_clustering(
                                st.session_state.X, n_clusters, random_state, 'k-means++', n_init, max_iter
                            )
                        elif algorithm_choice == 'K-means (Random Init)':
                            results = perform_direct_meta_clustering(
                                st.session_state.X, n_clusters, random_state, 'random', n_init, max_iter
                            )
                        else:
                            # Alternatif algoritmalar
                            algo_map = {
                                'Spectral Clustering': 'spectral',
                                'Agglomerative': 'agglomerative', 
                                'DBSCAN': 'dbscan'
                            }
                            results = perform_alternative_clustering(
                                st.session_state.X, algo_map[algorithm_choice], n_clusters, random_state
                            )
                        
                        if results:
                            progress_bar.progress(75)
                            status_text.text("SonuÃ§lar kaydediliyor...")
                            
                            st.session_state.direct_meta_labels = results['labels']
                            st.session_state.direct_meta_metrics = {
                                'silhouette_score': results['silhouette_score'],
                                'algorithm': f"Log BazÄ±nda {algorithm_choice}",
                                'clustering_type': 'log_based'
                            }
                            
                            # KÃ¼me merkezleri sadece K-means iÃ§in mevcut
                            if 'cluster_centers' in results:
                                st.session_state.direct_meta_cluster_centers = results['cluster_centers']
                            else:
                                st.session_state.direct_meta_cluster_centers = None
                                
                            st.session_state.meta_clustering_done = True
                            st.session_state.last_n_clusters = n_clusters
                            st.session_state.meta_results_visible = True
                            
                            progress_bar.progress(100)
                            status_text.success(f"Log bazÄ±nda {algorithm_choice} tamamlandÄ±!")
                            
                            st.balloons()
                            st.rerun()
        
        with col2:
            if st.button("ğŸ”€ FarklÄ± Seed Dene", use_container_width=True, key="meta_apply_random"):
                with st.spinner(f"FarklÄ± baÅŸlangÄ±Ã§ ile {clustering_type} kÃ¼meleme..."):
                    # Rastgele bir seed kullan
                    import time
                    random_seed = int(time.time()) % 10000
                    
                    if clustering_type == "NÃ¶ron BazÄ±nda":
                        # NÃ¶ron bazÄ±nda kÃ¼meleme
                        if hasattr(st.session_state, 'som') and st.session_state.som is not None:
                            som_weights = st.session_state.som.get_weights()
                            neuron_weights = som_weights.reshape(-1, som_weights.shape[-1])
                            
                            # NÃ¶ron kÃ¼meleme
                            neuron_results = perform_neuron_based_meta_clustering(
                                neuron_weights, n_clusters, random_seed
                            )
                            
                            if neuron_results:
                                # BMU koordinatlarÄ±nÄ± al
                                bmu_coords = np.array([st.session_state.som.winner(x) for x in st.session_state.X])
                                grid_size = int(np.sqrt(len(neuron_weights)))
                                
                                # LoglarÄ± nÃ¶ron kÃ¼melerine eÅŸle
                                log_labels = map_logs_to_neuron_clusters(
                                    bmu_coords, neuron_results['neuron_labels'], grid_size
                                )
                                
                                if log_labels is not None:
                                    # Log silÃ¼et skorunu hesapla
                                    if len(set(log_labels)) > 1:
                                        log_silhouette = silhouette_score(st.session_state.X, log_labels)
                                    else:
                                        log_silhouette = 0.0
                                    
                                    st.session_state.direct_meta_labels = log_labels
                                    st.session_state.direct_meta_metrics = {
                                        'silhouette_score': log_silhouette,
                                        'neuron_silhouette': neuron_results['neuron_silhouette'],
                                        'algorithm': f"NÃ¶ron BazÄ±nda {algorithm_choice} (Seed: {random_seed})",
                                        'clustering_type': 'neuron_based'
                                    }
                                    st.session_state.direct_meta_cluster_centers = neuron_results['cluster_centers']
                                    st.session_state.meta_clustering_done = True
                                    st.session_state.meta_results_visible = True
                                    
                                    st.success(f"NÃ¶ron bazÄ±nda Seed {random_seed} ile farklÄ± sonuÃ§ elde edildi!")
                                    st.rerun()
                                else:
                                    st.error("Log-nÃ¶ron eÅŸleme baÅŸarÄ±sÄ±z!")
                            else:
                                st.error("NÃ¶ron kÃ¼meleme baÅŸarÄ±sÄ±z!")
                        else:
                            st.error("SOM modeli bulunamadÄ±! Ã–nce SOM analizi yapÄ±n.")
                    
                    else:
                        # Log bazÄ±nda kÃ¼meleme (mevcut iÅŸlem)
                        if algorithm_choice.startswith('K-means'):
                            results = perform_direct_meta_clustering(
                                st.session_state.X, n_clusters, random_seed, 'random', n_init, max_iter
                            )
                        else:
                            algo_map = {
                                'Spectral Clustering': 'spectral',
                                'Agglomerative': 'agglomerative',
                                'DBSCAN': 'dbscan'
                            }
                            results = perform_alternative_clustering(
                                st.session_state.X, algo_map[algorithm_choice], n_clusters, random_seed
                            )
                        
                        if results:
                            st.session_state.direct_meta_labels = results['labels']
                            st.session_state.direct_meta_metrics = {
                                'silhouette_score': results['silhouette_score'],
                                'algorithm': f"Log BazÄ±nda {algorithm_choice} (Seed: {random_seed})",
                                'clustering_type': 'log_based'
                            }
                            
                            if 'cluster_centers' in results:
                                st.session_state.direct_meta_cluster_centers = results['cluster_centers']
                            else:
                                st.session_state.direct_meta_cluster_centers = None
                                
                            st.session_state.meta_clustering_done = True
                            st.session_state.meta_results_visible = True
                            
                            st.success(f"Log bazÄ±nda Seed {random_seed} ile farklÄ± sonuÃ§ elde edildi!")
                            st.rerun()

    with control_col2:
        st.markdown("""
            <div class="meta-control-card">
                <h4>KarÅŸÄ±laÅŸtÄ±rma AyarlarÄ±</h4>
            </div>
        """, unsafe_allow_html=True)
        
        # KarÅŸÄ±laÅŸtÄ±rma tÃ¼rÃ¼ seÃ§imi
        comparison_options = ["DoÄŸrudan K-means vs SOM", "SOM vs SOM Meta KÃ¼meleme"]
        
        selected_comparison = st.selectbox(
            "KarÅŸÄ±laÅŸtÄ±rma TÃ¼rÃ¼",
            options=comparison_options,
            index=comparison_options.index(st.session_state.comparison_type),
            help="Hangi kÃ¼meleme yaklaÅŸÄ±mlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak istediÄŸinizi seÃ§in",
            key="meta_comparison_select"
        )
        
        # SeÃ§im deÄŸiÅŸtiÄŸinde session state'i gÃ¼ncelle
        if selected_comparison != st.session_state.comparison_type:
            st.session_state.comparison_type = selected_comparison

        # KarÅŸÄ±laÅŸtÄ±rma butonu
        if st.button("KarÅŸÄ±laÅŸtÄ±r", type="secondary", use_container_width=True, key="meta_compare_button"):
            if not st.session_state.get("som_done", False):
                st.error("KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nce SOM analizi yapÄ±lmalÄ±!")
            elif not st.session_state.meta_clustering_done:
                st.error("KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nce meta kÃ¼meleme yapÄ±lmalÄ±!")
            else:
                with st.spinner("KarÅŸÄ±laÅŸtÄ±rma yapÄ±lÄ±yor..."):
                    comparison = compare_clustering_approaches(
                        st.session_state.X,
                        st.session_state.meta_clusters,
                        st.session_state.direct_meta_labels
                    )
                    if comparison:
                        st.session_state.comparison_results = comparison
                        st.success("KarÅŸÄ±laÅŸtÄ±rma tamamlandÄ±!")
                        st.rerun()

    # Durum kartlarÄ±
    if st.session_state.som_done or st.session_state.meta_clustering_done:
        st.markdown("### Durum Ã–zeti")
        status_col1, status_col2, status_col3 = st.columns(3)
        
        with status_col1:
            som_status = "TamamlandÄ±" if st.session_state.get("som_done", False) else "Beklemede"
            st.metric("SOM Analizi", som_status)
        
        with status_col2:
            meta_status = "TamamlandÄ±" if st.session_state.meta_clustering_done else "Beklemede"
            st.metric("Meta KÃ¼meleme", meta_status)
        
        with status_col3:
            comp_status = "TamamlandÄ±" if st.session_state.comparison_results else "Beklemede"
            st.metric("KarÅŸÄ±laÅŸtÄ±rma", comp_status)

    # SonuÃ§larÄ± gÃ¶ster
    if st.session_state.meta_clustering_done and st.session_state.direct_meta_labels is not None:
        st.markdown("---")
        st.markdown("### Meta KÃ¼meleme SonuÃ§larÄ±")
        
        # Ana metrikler
        metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
        
        with metric_col1:
            st.metric(
                "SilÃ¼et Skoru", 
                f"{st.session_state.direct_meta_metrics['silhouette_score']:.3f}",
                help="KÃ¼meleme kalitesi gÃ¶stergesi (0-1 arasÄ±, yÃ¼ksek=iyi)"
            )
            
            # KullanÄ±lan algoritma bilgisi
            if 'algorithm' in st.session_state.direct_meta_metrics:
                st.caption(f"ğŸ”§ Algoritma: {st.session_state.direct_meta_metrics['algorithm']}")
        
        with metric_col2:
            # NÃ¶ron bazÄ±nda kÃ¼meleme yapÄ±ldÄ±ysa nÃ¶ron silÃ¼et skorunu gÃ¶ster
            if (st.session_state.direct_meta_metrics.get('clustering_type') == 'neuron_based' and 
                'neuron_silhouette' in st.session_state.direct_meta_metrics):
                st.metric(
                    "NÃ¶ron SilÃ¼et Skoru", 
                    f"{st.session_state.direct_meta_metrics['neuron_silhouette']:.3f}",
                    help="NÃ¶ron kÃ¼meleme kalitesi (nÃ¶ronlarÄ±n ne kadar iyi kÃ¼melendiÄŸi)"
                )
            else:
                cluster_count = len(np.unique(st.session_state.direct_meta_labels))
                st.metric("KÃ¼me SayÄ±sÄ±", cluster_count)
        
        with metric_col3:
            cluster_count = len(np.unique(st.session_state.direct_meta_labels))
            if not (st.session_state.direct_meta_metrics.get('clustering_type') == 'neuron_based' and 
                    'neuron_silhouette' in st.session_state.direct_meta_metrics):
                data_count = len(st.session_state.direct_meta_labels)
                st.metric("Veri SayÄ±sÄ±", data_count)
            else:
                st.metric("KÃ¼me SayÄ±sÄ±", cluster_count)
        
        with metric_col4:
            data_count = len(st.session_state.direct_meta_labels)
            if (st.session_state.direct_meta_metrics.get('clustering_type') == 'neuron_based' and 
                'neuron_silhouette' in st.session_state.direct_meta_metrics):
                st.metric("Veri SayÄ±sÄ±", data_count)
            else:
                avg_cluster_size = data_count // len(np.unique(st.session_state.direct_meta_labels))
                st.metric("Ort. KÃ¼me Boyutu", avg_cluster_size)
        
        # NÃ¶ron bazÄ±nda kÃ¼meleme iÃ§in ek bilgiler
        if (st.session_state.direct_meta_metrics.get('clustering_type') == 'neuron_based' and 
            'neuron_silhouette' in st.session_state.direct_meta_metrics):
            
            st.markdown("### ğŸ§  NÃ¶ron BazÄ±nda KÃ¼meleme DetaylarÄ±")
            
            detail_col1, detail_col2, detail_col3 = st.columns(3)
            
            with detail_col1:
                avg_cluster_size = data_count // len(np.unique(st.session_state.direct_meta_labels))
                st.metric("Ort. KÃ¼me Boyutu", avg_cluster_size)
            
            with detail_col2:
                # Toplam nÃ¶ron sayÄ±sÄ±
                if hasattr(st.session_state, 'som') and st.session_state.som is not None:
                    som_weights = st.session_state.som.get_weights()
                    total_neurons = som_weights.shape[0] * som_weights.shape[1]
                    st.metric("Toplam NÃ¶ron", total_neurons)
            
            with detail_col3:
                # Aktif nÃ¶ron sayÄ±sÄ± (loglarÄ±n kullandÄ±ÄŸÄ±)
                if hasattr(st.session_state, 'df') and 'bmu_x' in st.session_state.df.columns:
                    unique_neurons = len(st.session_state.df[['bmu_x', 'bmu_y']].drop_duplicates())
                    st.metric("Aktif NÃ¶ron", unique_neurons)
            
            st.info("ğŸ” **NÃ¶ron BazÄ±nda KÃ¼meleme**: Ã–nce SOM nÃ¶ronlarÄ± kÃ¼melenir, sonra her log en yakÄ±n nÃ¶ronun kÃ¼mesine atanÄ±r. Bu yaklaÅŸÄ±m SOM'un Ã¶ÄŸrendiÄŸi topolojik yapÄ±yÄ± korur.")

        # GÃ¶rselleÅŸtirmeler
        with st.expander("GÃ¶rselleÅŸtirmeler", expanded=True):
            viz_col1, viz_col2 = st.columns([2, 1])
            
            with viz_col1:
                meta_plot = visualize_meta_clusters(
                    st.session_state.X,
                    st.session_state.direct_meta_labels,
                    st.session_state.last_n_clusters,
                    st.session_state.direct_meta_cluster_centers
                )
                if meta_plot:
                    st.pyplot(meta_plot)
            
            with viz_col2:
                # KÃ¼me daÄŸÄ±lÄ±mÄ±
                cluster_sizes = pd.Series(st.session_state.direct_meta_labels).value_counts().sort_index()
                st.markdown("**KÃ¼me DaÄŸÄ±lÄ±mÄ±:**")
                st.bar_chart(cluster_sizes)
                
                # KÃ¼me bilgileri
                st.markdown("**KÃ¼me DetaylarÄ±:**")
                for i, size in cluster_sizes.items():
                    percentage = (size / len(st.session_state.direct_meta_labels)) * 100
                    st.write(f"KÃ¼me {i}: {size} veri ({percentage:.1f}%)")

        # KÃ¼me Ã¶zeti tablosu
        try:
            cluster_means = pd.DataFrame(st.session_state.X).groupby(st.session_state.direct_meta_labels).mean()
            feature_names = [f"Ã–zellik {i+1}" for i in range(st.session_state.X.shape[1])]
            cluster_means.columns = feature_names
            
            with st.expander("KÃ¼me Ã–zeti Tablosu"):
                st.dataframe(
                    cluster_means.round(3), 
                    use_container_width=True,
                    height=300
                )
        except Exception as e:
            st.warning("KÃ¼me Ã¶zeti oluÅŸturulurken bir hata oluÅŸtu.")

    # KarÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ±
    if st.session_state.comparison_results is not None:
        st.markdown("---")
        st.markdown("### KarÅŸÄ±laÅŸtÄ±rma SonuÃ§larÄ±")
        
        comparison = st.session_state.comparison_results
        
        # KarÅŸÄ±laÅŸtÄ±rma metrikleri
        comp_col1, comp_col2, comp_col3 = st.columns(3)
        
        with comp_col1:
            ari_color = "green" if comparison['adjusted_rand_index'] > 0.5 else "orange" if comparison['adjusted_rand_index'] > 0.2 else "red"
            st.metric(
                "Adjusted Rand Index", 
                f"{comparison['adjusted_rand_index']:.3f}",
                help="KÃ¼meleme benzerliÄŸi (0-1 arasÄ±, yÃ¼ksek=benzer)"
            )
        
        with comp_col2:
            st.metric(
                "SOM SilÃ¼et Skoru", 
                f"{comparison['som_silhouette']:.3f}",
                help="SOM kÃ¼meleme kalitesi"
            )
        
        with comp_col3:
            st.metric(
                "Meta SilÃ¼et Skoru", 
                f"{comparison['meta_silhouette']:.3f}",
                help="Meta kÃ¼meleme kalitesi"
            )
        
        # Metrik yorumlarÄ±
        st.markdown("### ğŸ“Š Metrik YorumlarÄ±:")
        
        # ARI yorumu
        ari = comparison['adjusted_rand_index']
        if ari > 0.7:
            ari_interpretation = "ğŸŸ¢ **Ã‡ok YÃ¼ksek Benzerlik**: Ä°ki yÃ¶ntem neredeyse aynÄ± kÃ¼melemeyi yapÄ±yor"
        elif ari > 0.5:
            ari_interpretation = "ğŸŸ¡ **Orta-YÃ¼ksek Benzerlik**: Ä°ki yÃ¶ntem benzer ama farklÄ± kÃ¼melemeler yapÄ±yor"
        elif ari > 0.2:
            ari_interpretation = "ğŸŸ  **Orta Benzerlik**: Ä°ki yÃ¶ntem bazÄ± noktalarda benzer kÃ¼melemeler yapÄ±yor"
        else:
            ari_interpretation = "ğŸ”´ **DÃ¼ÅŸÃ¼k Benzerlik**: Ä°ki yÃ¶ntem oldukÃ§a farklÄ± kÃ¼melemeler yapÄ±yor"
        
        # SilÃ¼et skorlarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
        som_sil = comparison['som_silhouette']
        meta_sil = comparison['meta_silhouette']
        sil_diff = meta_sil - som_sil
        
        if abs(sil_diff) < 0.05:
            sil_interpretation = "âš–ï¸ **Benzer Kalite**: Ä°ki yÃ¶ntem de benzer kÃ¼meleme kalitesi gÃ¶steriyor"
        elif sil_diff > 0.1:
            sil_interpretation = "ğŸ“ˆ **Meta KÃ¼meleme Daha Ä°yi**: Meta kÃ¼meleme daha yÃ¼ksek kalite gÃ¶steriyor"
        elif sil_diff < -0.1:
            sil_interpretation = "ğŸ“‰ **SOM Daha Ä°yi**: SOM daha yÃ¼ksek kÃ¼meleme kalitesi gÃ¶steriyor"
        else:
            sil_interpretation = "ğŸ”„ **Hafif Fark**: Bir yÃ¶ntem diÄŸerinden biraz daha iyi performans gÃ¶steriyor"
        
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"**ARI Analizi:** {ari_interpretation}")
        with col2:
            st.info(f"**Kalite KarÅŸÄ±laÅŸtÄ±rmasÄ±:** {sil_interpretation}")
        
        # Ã–zet Ã¶neri
        st.markdown("### ğŸ’¡ Ã–neri:")
        if ari > 0.7 and abs(sil_diff) < 0.05:
            recommendation = "Her iki yÃ¶ntem de benzer sonuÃ§lar veriyor. SOM'un yorumlanabilirlik avantajÄ±nÄ± kullanabilirsiniz."
        elif meta_sil > som_sil + 0.1:
            recommendation = "Meta kÃ¼meleme daha iyi kalite gÃ¶steriyor. Daha hassas analiz iÃ§in meta kÃ¼melemeyi tercih edin."
        elif som_sil > meta_sil + 0.1:
            recommendation = "SOM daha iyi kÃ¼meleme kalitesi gÃ¶steriyor. Veri yapÄ±sÄ± SOM'a daha uygun olabilir."
        elif ari < 0.3:
            recommendation = "Ä°ki yÃ¶ntem farklÄ± kÃ¼meleme stratejileri uyguluyor. Her ikisini de analiz ederek daha kapsamlÄ± gÃ¶rÃ¼ÅŸ elde edebilirsiniz."
        else:
            recommendation = "Her iki yÃ¶ntem de geÃ§erli sonuÃ§lar veriyor. Analiz amacÄ±nÄ±za gÃ¶re birini seÃ§ebilirsiniz."
        
        st.success(f"ğŸ¯ {recommendation}")
        
        # GÃ¶rsel karÅŸÄ±laÅŸtÄ±rma
        with st.expander("GÃ¶rsel KarÅŸÄ±laÅŸtÄ±rma", expanded=True):
            st.markdown("**KarÅŸÄ±laÅŸtÄ±rma Modu SeÃ§in:**")
            comparison_mode = st.radio(
                "Hangi karÅŸÄ±laÅŸtÄ±rmayÄ± gÃ¶rmek istiyorsunuz?",
                ["AynÄ± Koordinat Sistemi (Adil KarÅŸÄ±laÅŸtÄ±rma)", "FarklÄ± Koordinat Sistemleri (DetaylÄ± Analiz)"],
                help="AynÄ± koordinat sistemi kÃ¼meleme kalitesini karÅŸÄ±laÅŸtÄ±rmak iÃ§in, farklÄ± sistemler her metodun kendi Ã¶zelliklerini gÃ¶rmek iÃ§in"
            )
            
            st.markdown("---")
            
            if comparison_mode == "AynÄ± Koordinat Sistemi (Adil KarÅŸÄ±laÅŸtÄ±rma)":
                st.markdown("**ğŸ“Š AynÄ± PCA koordinatlarÄ±nda her iki kÃ¼meleme sonucu:**")
                st.info("Bu gÃ¶rÃ¼nÃ¼m her iki algoritmanÄ±n aynÄ± veri Ã¼zerinde nasÄ±l kÃ¼meleme yaptÄ±ÄŸÄ±nÄ± gÃ¶rsel olarak karÅŸÄ±laÅŸtÄ±rmanÄ±zÄ± saÄŸlar.")
            else:
                st.markdown("**ğŸ” Her algoritmanÄ±n kendi doÄŸal koordinat sisteminde sonuÃ§larÄ±:**")
                st.info("SOM: NÃ¶ron grid koordinatlarÄ± | Meta: PCA koordinatlarÄ±")
            
            try:
                # Veri kontrolÃ¼ - NaN deÄŸerleri kontrol et
                X_data = st.session_state.X
                if np.any(np.isnan(X_data)) or np.any(np.isinf(X_data)):
                    st.warning("Veri setinde NaN deÄŸerler tespit edildi, temizleniyor...")
                    finite_mask = np.all(np.isfinite(X_data), axis=1)
                    X_clean = X_data[finite_mask]
                    som_labels_clean = st.session_state.som_labels[finite_mask]
                    meta_labels_clean = st.session_state.direct_meta_labels[finite_mask]
                    
                    # DataFrame'den BMU koordinatlarÄ±nÄ± al
                    if hasattr(st.session_state, 'df') and st.session_state.df is not None:
                        df_clean = st.session_state.df.iloc[finite_mask].copy()
                    else:
                        st.error("SOM BMU koordinatlarÄ± bulunamadÄ±!")
                        return
                else:
                    X_clean = X_data
                    som_labels_clean = st.session_state.som_labels
                    meta_labels_clean = st.session_state.direct_meta_labels
                    df_clean = st.session_state.df.copy()
                
                if len(X_clean) == 0:
                    st.error("Temizleme sonrasÄ± veri kalmadÄ±!")
                    return
                
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
                
                if comparison_mode == "AynÄ± Koordinat Sistemi (Adil KarÅŸÄ±laÅŸtÄ±rma)":
                    # Her iki grafik iÃ§in de aynÄ± PCA koordinatlarÄ±nÄ± kullan
                    if X_clean.shape[1] == 1:
                        # Tek Ã¶zellik varsa Ã¶zel iÅŸlem
                        coords_x = X_clean.flatten()
                        coords_y = np.zeros(len(X_clean))
                        explained_variance = [1.0, 0.0]
                    elif X_clean.shape[0] < 2:
                        st.error("GÃ¶rselleÅŸtirme iÃ§in en az 2 veri noktasÄ± gerekli!")
                        return
                    else:
                        # Standart PCA
                        pca = PCA(n_components=min(2, X_clean.shape[1]))
                        pca_coords = pca.fit_transform(X_clean)
                        explained_variance = pca.explained_variance_ratio_
                        
                        # Tek boyutlu sonuÃ§ varsa ikinci boyutu sÄ±fÄ±r ekle
                        if pca_coords.shape[1] == 1:
                            coords_x = pca_coords[:, 0]
                            coords_y = np.zeros(len(pca_coords))
                            explained_variance = np.append(explained_variance, 0.0)
                        else:
                            coords_x = pca_coords[:, 0]
                            coords_y = pca_coords[:, 1]
                    
                    # SOM sonuÃ§larÄ± - PCA koordinatlarÄ±
                    scatter1 = ax1.scatter(coords_x, coords_y, 
                                         c=som_labels_clean,
                                         cmap='viridis', alpha=0.7, s=50)
                    ax1.set_title('SOM KÃ¼meleme', fontsize=14, fontweight='bold')
                    ax1.set_xlabel(f'PC1 ({explained_variance[0]:.2%})')
                    ax1.set_ylabel(f'PC2 ({explained_variance[1]:.2%})')
                    plt.colorbar(scatter1, ax=ax1, label='SOM KÃ¼me')
                    ax1.grid(True, alpha=0.3)
                    
                    # Meta kÃ¼meleme sonuÃ§larÄ± - AynÄ± PCA koordinatlarÄ±
                    scatter2 = ax2.scatter(coords_x, coords_y, 
                                         c=meta_labels_clean,
                                         cmap='viridis', alpha=0.7, s=50)
                    ax2.set_title('Meta KÃ¼meleme', fontsize=14, fontweight='bold')
                    ax2.set_xlabel(f'PC1 ({explained_variance[0]:.2%})')
                    ax2.set_ylabel(f'PC2 ({explained_variance[1]:.2%})')
                    plt.colorbar(scatter2, ax=ax2, label='Meta KÃ¼me')
                    ax2.grid(True, alpha=0.3)
                    
                    # KÃ¼me Ã¶rtÃ¼ÅŸme analizi
                    st.markdown("### ğŸ”— KÃ¼me Ã–rtÃ¼ÅŸme Analizi:")
                    try:
                        # Ã–rtÃ¼ÅŸme matrisi oluÅŸtur
                        overlap_matrix = pd.crosstab(
                            som_labels_clean, 
                            meta_labels_clean, 
                            normalize='index'
                        ).round(3)
                        overlap_matrix.index.name = 'SOM KÃ¼me'
                        overlap_matrix.columns.name = 'Meta KÃ¼me'
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.markdown("**Ã–rtÃ¼ÅŸme Matrisi (SatÄ±r YÃ¼zdesi):**")
                            st.dataframe(
                                overlap_matrix.style.background_gradient(cmap='RdYlBu_r'),
                                use_container_width=True
                            )
                            st.caption("Her hÃ¼cre: SOM kÃ¼mesindeki loglarÄ±n ne kadarlÄ±k kÄ±smÄ±nÄ±n belirtilen Meta kÃ¼mede olduÄŸunu gÃ¶sterir")
                        
                        with col2:
                            # En yÃ¼ksek Ã¶rtÃ¼ÅŸmeleri bul
                            max_overlaps = []
                            for som_cluster in overlap_matrix.index:
                                max_meta = overlap_matrix.loc[som_cluster].idxmax()
                                max_value = overlap_matrix.loc[som_cluster, max_meta]
                                max_overlaps.append({
                                    'SOM': som_cluster,
                                    'Meta': max_meta, 
                                    'Ã–rtÃ¼ÅŸme': f"{max_value:.1%}"
                                })
                            
                            overlap_df = pd.DataFrame(max_overlaps)
                            st.markdown("**En GÃ¼Ã§lÃ¼ EÅŸleÅŸmeler:**")
                            st.dataframe(overlap_df, hide_index=True)
                            
                            # Ortalama Ã¶rtÃ¼ÅŸme
                            avg_overlap = np.diagonal(overlap_matrix.values).mean()
                            st.metric("Ort. Diagonal Ã–rtÃ¼ÅŸme", f"{avg_overlap:.1%}")
                            
                    except Exception as e:
                        st.warning(f"Ã–rtÃ¼ÅŸme analizi yapÄ±lamadÄ±: {str(e)}")
                    
                else:
                    # FarklÄ± koordinat sistemleri (Ã¶nceki versiyon)
                    # SOM iÃ§in BMU koordinatlarÄ±nÄ± kullan
                    if 'bmu_x' in df_clean.columns and 'bmu_y' in df_clean.columns:
                        som_x = df_clean['bmu_x'].values
                        som_y = df_clean['bmu_y'].values
                    else:
                        st.error("BMU koordinatlarÄ± (bmu_x, bmu_y) bulunamadÄ±!")
                        return
                    
                    # Meta kÃ¼meleme iÃ§in PCA koordinatlarÄ±nÄ± kullan
                    if X_clean.shape[1] == 1:
                        # Tek Ã¶zellik varsa Ã¶zel iÅŸlem
                        meta_x = X_clean.flatten()
                        meta_y = np.zeros(len(X_clean))
                        explained_variance = [1.0, 0.0]
                    elif X_clean.shape[0] < 2:
                        st.error("GÃ¶rselleÅŸtirme iÃ§in en az 2 veri noktasÄ± gerekli!")
                        return
                    else:
                        # Standart PCA
                        pca = PCA(n_components=min(2, X_clean.shape[1]))
                        meta_coords = pca.fit_transform(X_clean)
                        explained_variance = pca.explained_variance_ratio_
                        
                        # Tek boyutlu sonuÃ§ varsa ikinci boyutu sÄ±fÄ±r ekle
                        if meta_coords.shape[1] == 1:
                            meta_x = meta_coords[:, 0]
                            meta_y = np.zeros(len(meta_coords))
                            explained_variance = np.append(explained_variance, 0.0)
                        else:
                            meta_x = meta_coords[:, 0]
                            meta_y = meta_coords[:, 1]
                    
                    # SOM sonuÃ§larÄ± - BMU grid koordinatlarÄ±
                    scatter1 = ax1.scatter(som_x, som_y, 
                                         c=som_labels_clean,
                                         cmap='viridis', alpha=0.7, s=50)
                    ax1.set_title('SOM KÃ¼meleme (BMU Grid)', fontsize=14, fontweight='bold')
                    ax1.set_xlabel('BMU X KoordinatÄ±')
                    ax1.set_ylabel('BMU Y KoordinatÄ±')
                    plt.colorbar(scatter1, ax=ax1, label='SOM KÃ¼me')
                    ax1.grid(True, alpha=0.3)
                    
                    # Meta kÃ¼meleme sonuÃ§larÄ± - PCA koordinatlarÄ±
                    scatter2 = ax2.scatter(meta_x, meta_y, 
                                         c=meta_labels_clean,
                                         cmap='viridis', alpha=0.7, s=50)
                    ax2.set_title('Meta KÃ¼meleme (PCA)', fontsize=14, fontweight='bold')
                    ax2.set_xlabel(f'PC1 ({explained_variance[0]:.2%})')
                    ax2.set_ylabel(f'PC2 ({explained_variance[1]:.2%})')
                    plt.colorbar(scatter2, ax=ax2, label='Meta KÃ¼me')
                    ax2.grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig)
                
            except Exception as e:
                st.error(f"KarÅŸÄ±laÅŸtÄ±rma gÃ¶rselleÅŸtirme hatasÄ±: {str(e)}")
                import traceback
                st.error(f"Detay: {traceback.format_exc()}")
                
                # Hata durumunda basit metin Ã§Ä±ktÄ±sÄ±
                st.info("GÃ¶rselleÅŸtirme baÅŸarÄ±sÄ±z, metrik bilgiler:")
                st.write(f"- SOM KÃ¼me SayÄ±sÄ±: {len(np.unique(st.session_state.som_labels))}")
                st.write(f"- Meta KÃ¼me SayÄ±sÄ±: {len(np.unique(st.session_state.direct_meta_labels))}")
                st.write(f"- Veri Boyutu: {st.session_state.X.shape}")
                st.write(f"- ARI Skoru: {comparison['adjusted_rand_index']:.3f}")

    # EÄŸer hiÃ§ analiz yapÄ±lmamÄ±ÅŸsa bilgilendirici mesaj
    if not st.session_state.meta_clustering_done:
        st.markdown("---")
        st.info("""
        **BaÅŸlamak iÃ§in:** YukarÄ±daki kontrol panelinden kÃ¼me sayÄ±sÄ±nÄ± ayarlayÄ±n ve "Meta KÃ¼meleme BaÅŸlat" butonuna tÄ±klayÄ±n.
        
        **Not:** Meta kÃ¼meleme analizi iÃ§in SOM modelinin eÄŸitilmiÅŸ olmasÄ± gerekmektedir.
        """) 