import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import numpy as np
import pandas as pd
import io
import base64
import matplotlib.pyplot as plt

# BytesIO gÃ¶rsellerini doÄŸrudan StreamLit'te gÃ¶stermek iÃ§in
def show_matplotlib_figure(fig_buffer):
    if isinstance(fig_buffer, io.BytesIO):
        fig_buffer.seek(0)
        st.image(fig_buffer)
    elif isinstance(fig_buffer, str):
        # Base64 string ise BytesIO'ya Ã§evir
        buffer = io.BytesIO(base64.b64decode(fig_buffer))
        buffer.seek(0)
        st.image(buffer)
    else:
        st.warning("GÃ¶rselleÅŸtirme gÃ¶sterilemiyor.")

# BytesIO'yu base64 string'e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yardÄ±mcÄ± fonksiyon
def _buffer_to_base64(buffer):
    buffer.seek(0)
    img_str = base64.b64encode(buffer.read()).decode()
    return img_str

# Base64 string'i BytesIO'ya dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yardÄ±mcÄ± fonksiyon
def _base64_to_buffer(base64_str):
    buffer = io.BytesIO(base64.b64decode(base64_str))
    buffer.seek(0)
    return buffer

def show_summary_table():
    st.subheader("NÃ¶ron BazÄ±nda Ã–zet Tablosu")
    with st.expander("Bu Tablo Ne Anlama Geliyor?"):
        st.write("""
        Bu tablo, SOM Ä±zgarasÄ±ndaki her nÃ¶ronun (BMU) Ã¶zet istatistiklerini gÃ¶sterir. Her nÃ¶ron, benzer loglarÄ± temsil eder. 
        Tablo, nÃ¶ronun koordinatlarÄ±nÄ±, engellenmiÅŸ istek oranÄ±nÄ±, en sÄ±k URI'yi, ortalama niceleme hatasÄ±nÄ± ve log sayÄ±sÄ±nÄ± iÃ§erir.
        - **YÃ¼ksek engellenmiÅŸ oranÄ±**: Potansiyel gÃ¼venlik tehditlerini iÅŸaret edebilir.
        - **YÃ¼ksek niceleme hatasÄ±**: Anormal davranÄ±ÅŸlarÄ± gÃ¶sterebilir.
        """)
    
    if 'summary_df' not in st.session_state or st.session_state.summary_df is None:
        create_summary_table()
    st.dataframe(st.session_state.summary_df)

def create_summary_table():
    df = st.session_state.df
    if 'bmu_x' not in df.columns or 'bmu_y' not in df.columns:
        st.error("BMU koordinatlarÄ± bulunamadÄ±!")
        return
    
    # SÃ¼tun kontrolleri ve gerekirse alternatif sÃ¼tunlarÄ± kullan
    agg_dict = {}
    
    # Engellenme oranÄ± sÃ¼tunu
    if 'transaction.is_interrupted' in df.columns:
        agg_dict['transaction.is_interrupted'] = 'mean'
    elif 'is_interrupted' in df.columns:
        agg_dict['is_interrupted'] = 'mean'
    else:
        st.warning("Engellenme oranÄ± sÃ¼tunu bulunamadÄ±!")
    
    # URI sÃ¼tunu
    if 'transaction.request.uri' in df.columns:
        agg_dict['transaction.request.uri'] = lambda x: x.mode()[0] if not x.empty and len(x.mode()) > 0 else 'Yok'
    elif 'request.uri' in df.columns:
        agg_dict['request.uri'] = lambda x: x.mode()[0] if not x.empty and len(x.mode()) > 0 else 'Yok'
    elif 'request_uri' in df.columns:
        agg_dict['request_uri'] = lambda x: x.mode()[0] if not x.empty and len(x.mode()) > 0 else 'Yok'
    else:
        st.warning("URI sÃ¼tunu bulunamadÄ±!")
    
    # Niceleme hatasÄ± sÃ¼tunu
    if 'quantization_error' in df.columns:
        agg_dict['quantization_error'] = 'mean'
    
    # Log sayÄ±sÄ± iÃ§in herhangi bir sayÄ±sal sÃ¼tun
    if 'transaction.client_port' in df.columns:
        agg_dict['transaction.client_port'] = 'count'
    elif 'client_port' in df.columns:
        agg_dict['client_port'] = 'count'
    else:
        # Ä°lk sayÄ±sal sÃ¼tunu bul
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            agg_dict[numeric_cols[0]] = 'count'
        else:
            # Herhangi bir sÃ¼tun kullan
            agg_dict[df.columns[0]] = 'count'
    
    # Agregasyon yapacak sÃ¼tun yoksa uyarÄ± ver ve Ã§Ä±k
    if not agg_dict:
        st.error("Ã–zet tablo iÃ§in gerekli sÃ¼tunlar bulunamadÄ±!")
        return
    
    # Ã–zet tabloyu oluÅŸtur
    summary = df.groupby(['bmu_x', 'bmu_y']).agg(agg_dict).reset_index()
    
    # SÃ¼tun isimlerini dÃ¼zelt
    rename_dict = {'bmu_x': 'BMU_X', 'bmu_y': 'BMU_Y'}
    
    for old_col, agg_func in agg_dict.items():
        if old_col in ['transaction.is_interrupted', 'is_interrupted']:
            rename_dict[old_col] = 'Engellenme OranÄ±'
        elif old_col in ['transaction.request.uri', 'request.uri', 'request_uri']:
            rename_dict[old_col] = 'En SÄ±k URI'
        elif old_col == 'quantization_error':
            rename_dict[old_col] = 'Ort. Hata'
        elif agg_func == 'count':
            rename_dict[old_col] = 'Log SayÄ±sÄ±'
    
    summary = summary.rename(columns=rename_dict)
    
    # NÃ¶ron sÃ¼tunu ekle
    summary['NÃ¶ron'] = summary.apply(lambda row: f"({row['BMU_X']},{row['BMU_Y']})", axis=1)
    st.session_state.summary_df = summary

def show_visualizations():
    st.subheader("EtkileÅŸimli GÃ¶rselleÅŸtirmeler")
    with st.expander("Bu Grafikler Ne Anlama Geliyor?"):
        st.write("""
        Bu grafikler, log verilerinin SOM Ä±zgarasÄ±ndaki daÄŸÄ±lÄ±mÄ±nÄ± ve niceleme hatasÄ± deÄŸerlerini gÃ¶sterir.
        - **SOM Izgara DaÄŸÄ±lÄ±mÄ±**: Her nokta bir log kaydÄ±nÄ± temsil eder. Renkler niceleme hatasÄ±nÄ± gÃ¶sterir. 
          Mavi (dÃ¼ÅŸÃ¼k hata) normal davranÄ±ÅŸlarÄ±, kÄ±rmÄ±zÄ± (yÃ¼ksek hata) potansiyel anomalileri iÅŸaret eder.
        - **Niceleme HatasÄ± DaÄŸÄ±lÄ±mÄ±**: LoglarÄ±n niceleme hatasÄ± deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir.
          YÃ¼ksek deÄŸerler (saÄŸda) potansiyel anomalileri temsil eder.
        """)
    
    create_scatter_plot()
    create_error_distribution()
    create_time_series_analysis()
    create_uri_distribution()
    create_heatmap()

def create_scatter_plot():
    df = st.session_state.df
    
    # Hover data seÃ§eneklerini kontrol et
    hover_data = []
    if 'transaction.client_port' in df.columns:
        hover_data.append('transaction.client_port')
    elif 'client_port' in df.columns:
        hover_data.append('client_port')
        
    if 'transaction.request.uri' in df.columns:
        hover_data.append('transaction.request.uri')
    elif 'request.uri' in df.columns:
        hover_data.append('request.uri')
    elif 'request_uri' in df.columns:
        hover_data.append('request_uri')
        
    if 'transaction.is_interrupted' in df.columns:
        hover_data.append('transaction.is_interrupted')
    elif 'is_interrupted' in df.columns:
        hover_data.append('is_interrupted')
    
    # Scatter plot oluÅŸtur
    fig = px.scatter(
        df,
        x='bmu_x',
        y='bmu_y',
        color='quantization_error',
        hover_data=hover_data,
        title='SOM Izgara DaÄŸÄ±lÄ±mÄ±',
        color_continuous_scale='Viridis'
    )
    fig.update_layout(
        legend_title_text='Niceleme HatasÄ±',
        legend=dict(itemsizing='constant')
    )
    st.plotly_chart(fig)
    st.markdown("**Lejant:** Renkler, niceleme hatasÄ± deÄŸerlerini gÃ¶sterir. Daha yÃ¼ksek deÄŸerler (kÄ±rmÄ±zÄ±), potansiyel anomalileri iÅŸaret eder.")

def create_error_distribution():
    fig = px.histogram(
        st.session_state.df,
        x='quantization_error',
        nbins=50,
        title='Niceleme HatasÄ± DaÄŸÄ±lÄ±mÄ±'
    )
    st.plotly_chart(fig)

def create_time_series_analysis():
    st.subheader("Zaman Serisi Analizi")
    with st.expander("Bu Grafik Ne Anlama Geliyor?"):
        st.write("""
        Bu grafik, saat bazÄ±nda engellenmiÅŸ istek oranÄ±nÄ± gÃ¶sterir. Ã–rneÄŸin, belirli saatlerde engellenmiÅŸ 
        isteklerin artmasÄ±, bir saldÄ±rÄ± giriÅŸimini iÅŸaret edebilir.
        """)
    
    df = st.session_state.df
    
    # Saat sÃ¼tunu kontrolÃ¼
    if 'hour' in df.columns:
        # Engellenme sÃ¼tunu kontrolÃ¼
        interrupted_col = None
        if 'transaction.is_interrupted' in df.columns:
            interrupted_col = 'transaction.is_interrupted'
        elif 'is_interrupted' in df.columns:
            interrupted_col = 'is_interrupted'
        
        if interrupted_col:
            try:
                # Zamansal veriye gÃ¶re gruplama yap
                time_series = df.groupby('hour')[interrupted_col].mean().reset_index()
                
                # Saat deÄŸerlerinin tam sayÄ±lardan oluÅŸtuÄŸunu doÄŸrula
                time_series['hour'] = time_series['hour'].astype(int)
                
                # Saatleri sÄ±rala
                time_series = time_series.sort_values('hour')
                
                # Ä°nteraktif Ã§izgi grafiÄŸi oluÅŸtur
                fig = px.line(
                    time_series, 
                    x='hour', 
                    y=interrupted_col,
                    title='Saat BazÄ±nda EngellenmiÅŸ Ä°stek OranÄ±',
                    labels={interrupted_col: 'Engellenme OranÄ±', 'hour': 'Saat'},
                    markers=True
                )
                
                # GrafiÄŸi iyileÅŸtir
                fig.update_layout(
                    xaxis=dict(
                        tickmode='array',
                        tickvals=list(range(0, 24)),
                        ticktext=[f"{h:02d}:00" for h in range(0, 24)]
                    ),
                    yaxis=dict(
                        tickformat='.2%',
                        title='Engellenme OranÄ±'
                    ),
                    hovermode='x unified'
                )
                
                # AyrÄ±ca bu veriler iÃ§in bir bar grafiÄŸi de ekle
                fig2 = px.bar(
                    time_series,
                    x='hour',
                    y=interrupted_col,
                    title='Saat BazÄ±nda EngellenmiÅŸ Ä°stek SayÄ±sÄ±',
                    labels={interrupted_col: 'Engellenme OranÄ±', 'hour': 'Saat'},
                    color=interrupted_col,
                    color_continuous_scale='Viridis'
                )
                
                fig2.update_layout(
                    xaxis=dict(
                        tickmode='array',
                        tickvals=list(range(0, 24)),
                        ticktext=[f"{h:02d}:00" for h in range(0, 24)]
                    ),
                    yaxis=dict(
                        tickformat='.2%',
                        title='Engellenme OranÄ±'
                    )
                )
                
                # Grafikleri gÃ¶ster
                col1, col2 = st.columns(2)
                
                with col1:
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    st.plotly_chart(fig2, use_container_width=True)
                    
                # Ä°steÄŸe baÄŸlÄ±, ayrÄ±ca saat bazÄ±nda istek sayÄ±sÄ± analizi ekle
                st.subheader("Saat BazÄ±nda Ä°stek SayÄ±sÄ± Analizi")
                
                # Her saatteki toplam istek sayÄ±sÄ±nÄ± hesapla
                request_count = df.groupby('hour').size().reset_index(name='istek_sayisi')
                request_count['hour'] = request_count['hour'].astype(int)
                request_count = request_count.sort_values('hour')
                
                # Ä°stek sayÄ±sÄ± grafiÄŸi
                fig3 = px.bar(
                    request_count,
                    x='hour',
                    y='istek_sayisi',
                    title='Saat BazÄ±nda Toplam Ä°stek SayÄ±sÄ±',
                    labels={'istek_sayisi': 'Ä°stek SayÄ±sÄ±', 'hour': 'Saat'},
                    color='istek_sayisi',
                    color_continuous_scale='Viridis'
                )
                
                fig3.update_layout(
                    xaxis=dict(
                        tickmode='array',
                        tickvals=list(range(0, 24)),
                        ticktext=[f"{h:02d}:00" for h in range(0, 24)]
                    ),
                    yaxis=dict(
                        title='Ä°stek SayÄ±sÄ±'
                    )
                )
                
                st.plotly_chart(fig3)
                
            except Exception as e:
                st.error(f"Zaman serisi analizi oluÅŸturulurken hata: {str(e)}")
                st.warning("Zaman serisi verilerinde beklenmeyen bir format tespit edildi.")
        else:
            st.warning("Engellenme oranÄ± sÃ¼tunu bulunamadÄ±.")
    else:
        st.warning("Zaman serisi analizi iÃ§in 'hour' sÃ¼tunu bulunamadÄ±.")
        # Zaman sÃ¼tununu otomatik oluÅŸturmayÄ± dene
        if 'transaction.timestamp' in df.columns:
            st.info("'transaction.timestamp' sÃ¼tunu bulundu. Saatlik analiz iÃ§in bu sÃ¼tunu kullanmak ister misiniz?")
            if st.button("Saat SÃ¼tunu OluÅŸtur"):
                try:
                    # Timestamp sÃ¼tununu datetime formatÄ±na Ã§evir
                    df['transaction.timestamp'] = pd.to_datetime(df['transaction.timestamp'], errors='coerce', format='mixed')
                    # Saat bilgisini Ã§Ä±kar
                    df['hour'] = df['transaction.timestamp'].dt.hour
                    st.session_state.df = df
                    st.success("Saat sÃ¼tunu baÅŸarÄ±yla oluÅŸturuldu. SayfayÄ± yenileyerek analizi gÃ¶rÃ¼ntÃ¼leyebilirsiniz.")
                    st.rerun()
                except Exception as e:
                    st.error(f"Saat sÃ¼tunu oluÅŸturulurken hata: {str(e)}")
        elif 'timestamp' in df.columns:
            st.info("'timestamp' sÃ¼tunu bulundu. Saatlik analiz iÃ§in bu sÃ¼tunu kullanmak ister misiniz?")
            if st.button("Saat SÃ¼tunu OluÅŸtur"):
                try:
                    # Timestamp sÃ¼tununu datetime formatÄ±na Ã§evir
                    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', format='mixed')
                    # Saat bilgisini Ã§Ä±kar
                    df['hour'] = df['timestamp'].dt.hour
                    st.session_state.df = df
                    st.success("Saat sÃ¼tunu baÅŸarÄ±yla oluÅŸturuldu. SayfayÄ± yenileyerek analizi gÃ¶rÃ¼ntÃ¼leyebilirsiniz.")
                    st.rerun()
                except Exception as e:
                    st.error(f"Saat sÃ¼tunu oluÅŸturulurken hata: {str(e)}")

def create_uri_distribution():
    st.subheader("En SÄ±k URI'lerin DaÄŸÄ±lÄ±mÄ±")
    with st.expander("Bu Grafik Ne Anlama Geliyor?"):
        st.write("""
        Bu pasta grafik, loglardaki en sÄ±k URI'lerin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir. En bÃ¼yÃ¼k dilimler, 
        sistemde en Ã§ok eriÅŸilen endpoint'leri temsil eder. Ã–rneÄŸin, `/login` bÃ¼yÃ¼k bir dilimse, 
        bu endpoint sÄ±kÃ§a hedefleniyor demektir.
        """)
    
    df = st.session_state.df
    
    # URI sÃ¼tunu kontrolÃ¼
    uri_col = None
    if 'transaction.request.uri' in df.columns:
        uri_col = 'transaction.request.uri'
    elif 'request.uri' in df.columns:
        uri_col = 'request.uri'
    elif 'request_uri' in df.columns:
        uri_col = 'request_uri'
        
    if uri_col:
        # URI'leri kÄ±saltma fonksiyonu
        def shorten_uri(uri, max_len=30):
            if isinstance(uri, str) and len(uri) > max_len:
                return uri[:max_len-3] + '...'
            return uri
            
        # URI deÄŸerlerini kÄ±salt ve sayÄ±mlarÄ± al
        uri_counts = df[uri_col].value_counts().head(10)
        
        # OkunabilirliÄŸi artÄ±rmak iÃ§in URI etiketlerini kÄ±salt
        shortened_uris = {shorten_uri(uri): count for uri, count in uri_counts.items()}
        
        # KÄ±sa aÃ§Ä±klamalar iÃ§in tooltip
        hover_template = '<b>%{label}</b><br>SayÄ±: %{value}<br>Oran: %{percent}'
        
        fig = px.pie(
            values=list(shortened_uris.values()),
            names=list(shortened_uris.keys()),
            title='En SÄ±k URI\'lerin DaÄŸÄ±lÄ±mÄ±',
            hover_data=[list(uri_counts.keys())],  # Tam URI'yi hover'da gÃ¶ster
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig)
    else:
        st.warning("URI daÄŸÄ±lÄ±mÄ± iÃ§in gerekli sÃ¼tun bulunamadÄ±.")

def create_heatmap():
    st.subheader("SOM IzgarasÄ± IsÄ± HaritasÄ±")
    with st.expander("Bu Grafik Ne Anlama Geliyor?"):
        st.write("""
        Bu Ä±sÄ± haritasÄ±, SOM Ä±zgarasÄ±ndaki nÃ¶ronlar arasÄ±ndaki mesafeleri gÃ¶sterir. 
        Daha koyu renkler, nÃ¶ronlar arasÄ±nda daha bÃ¼yÃ¼k farklÄ±lÄ±klarÄ± (yani farklÄ± davranÄ±ÅŸ modellerini) temsil eder.
        """)
    
    if st.session_state.som is not None:
        fig = px.imshow(
            st.session_state.som.distance_map().T, 
            color_continuous_scale='viridis', 
            title='SOM IzgarasÄ± IsÄ± HaritasÄ±'
        )
        st.plotly_chart(fig)
    else:
        st.warning("SOM modeli bulunamadÄ±.")

def handle_meta_clustering():
    st.subheader("Meta KÃ¼meleme Analizi")
    with st.expander("Meta-KÃ¼meleme Nedir?"):
        st.write("""
        Meta-kÃ¼meleme, SOM nÃ¶ronlarÄ±nÄ± K-means algoritmasÄ±yla daha bÃ¼yÃ¼k kÃ¼melere ayÄ±rÄ±r. 
        Bu, log verilerindeki geniÅŸ davranÄ±ÅŸ modellerini tespit etmeye yardÄ±mcÄ± olur. 
        Her meta-kÃ¼me, benzer Ã¶zelliklere sahip loglarÄ± temsil eder.
        Ã–rnek: Bir meta-kÃ¼me, `/login` endpoint'ine yÃ¶nelik ÅŸÃ¼pheli istekleri iÃ§erebilir 
        ve yÃ¼ksek engellenmiÅŸ istek oranÄ±yla dikkat Ã§ekebilir.
        """)
    
    n_clusters = st.slider("Meta KÃ¼me SayÄ±sÄ±", 2, 25, 5)
    
    # KMeans sÄ±nÄ±fÄ±nÄ± sadece bir kez import et
    from sklearn.cluster import KMeans
    
    try:
        # SOM aÄŸÄ±rlÄ±klarÄ±nÄ± bir kez hesapla ve diÄŸer fonksiyonlarda kullanmak iÃ§in session_state'e kaydet
        if 'som_weights_reshaped' not in st.session_state or st.session_state.som_weights_reshaped is None:
            # Som aÄŸÄ±rlÄ±k ÅŸeklini ve X verisi boyutunu belirle
            som_weights = st.session_state.som.get_weights()
            weights_shape = som_weights.shape
            
            # AÄŸÄ±rlÄ±klarÄ± dÃ¼zleÅŸtir
            grid_size = weights_shape[0]  # SOM Ä±zgara boyutu
            feature_dim = weights_shape[2]  # Ã–zellik boyutu
            
            # AÄŸÄ±rlÄ±klarÄ± yeniden ÅŸekillendirme
            weights = som_weights.reshape(grid_size * grid_size, feature_dim)
            st.session_state.som_weights_reshaped = weights
        else:
            weights = st.session_state.som_weights_reshaped
        
        kmeans = KMeans(n_clusters=n_clusters)
        meta_clusters = kmeans.fit_predict(weights)
        
        # SOM Ä±zgarasÄ±ndaki her hÃ¼cre iÃ§in meta kÃ¼me etiketlerini oluÅŸtur
        grid_size = st.session_state.som.get_weights().shape[0]  # SOM Ä±zgara boyutu
        meta_cluster_map = {}
        
        # Her BMU koordinatÄ± iÃ§in ilgili meta kÃ¼me etiketini eÅŸleÅŸtir
        for i in range(grid_size):
            for j in range(grid_size):
                # (i,j) koordinatÄ±ndaki hÃ¼crenin meta kÃ¼me etiketi
                meta_cluster_map[(i, j)] = meta_clusters[i * grid_size + j]
        
        # Her veri noktasÄ±na BMU koordinatlarÄ±na gÃ¶re meta kÃ¼me etiketi ata
        df_meta = st.session_state.df.copy()
        df_meta['meta_cluster'] = df_meta.apply(
            lambda row: meta_cluster_map.get((int(row['bmu_x']), int(row['bmu_y'])), -1), 
            axis=1
        )
        
        # Meta kÃ¼meleri session state'e kaydet
        st.session_state.meta_clusters = meta_clusters
        st.session_state.df_meta = df_meta
        
        # Meta kÃ¼me daÄŸÄ±lÄ±mÄ± grafiÄŸi
        fig = px.scatter(
            df_meta,
            x='bmu_x',
            y='bmu_y',
            color='meta_cluster',
            hover_data=['meta_cluster'],
            title='Meta KÃ¼me DaÄŸÄ±lÄ±mÄ±',
            color_discrete_sequence=px.colors.qualitative.Plotly
        )
        st.plotly_chart(fig)
        
        # Meta kÃ¼me Ã¶zet istatistikleri iÃ§in sÃ¼tun kontrolÃ¼
        agg_dict = {}
        
        # Engellenme oranÄ± sÃ¼tunu
        if 'transaction.is_interrupted' in df_meta.columns:
            agg_dict['transaction.is_interrupted'] = 'mean'
        elif 'is_interrupted' in df_meta.columns:
            agg_dict['is_interrupted'] = 'mean'
            
        # URI sÃ¼tunu
        uri_cols = ['transaction.request.uri', 'request.uri', 'request_uri']
        uri_col = next((col for col in uri_cols if col in df_meta.columns), None)
        if uri_col:
            agg_dict[uri_col] = lambda x: x.mode()[0] if not x.empty and len(x.mode()) > 0 else 'Yok'
            
        # Niceleme hatasÄ± iÃ§in Ã¶zet deÄŸerler
        if 'quantization_error' in df_meta.columns:
            agg_dict['quantization_error'] = ['mean', 'std', 'min', 'max']
            
        # Log sayÄ±sÄ± iÃ§in herhangi bir sÃ¼tun
        count_cols = ['transaction.client_port', 'client_port']
        count_col = next((col for col in count_cols if col in df_meta.columns), df_meta.columns[0])
        agg_dict[count_col] = 'count'
        
        if agg_dict:
            meta_summary = df_meta.groupby('meta_cluster').agg(agg_dict).reset_index()
            
            # SÃ¼tun isimleri
            col_names = ['Meta KÃ¼me']
            if any(col in agg_dict for col in ['transaction.is_interrupted', 'is_interrupted']):
                col_names.append('Engellenme OranÄ±')
            if uri_col:
                col_names.append('En SÄ±k URI')
            col_names.append('Log SayÄ±sÄ±')
            
            # SÃ¼tun sayÄ±sÄ± kontrolÃ¼
            if len(meta_summary.columns) == len(col_names):
                meta_summary.columns = col_names
                st.write("#### Meta KÃ¼me Ã–zet Ä°statistikleri")
                st.table(meta_summary)
            else:
                st.warning("Meta kÃ¼me Ã¶zeti oluÅŸturulurken sÃ¼tun sayÄ±sÄ± uyumsuzluÄŸu nedeniyle tablo gÃ¶rÃ¼ntÃ¼lenemiyor.")
                st.write("Ham Meta KÃ¼me Verileri:")
                st.dataframe(meta_summary)
        
        # Meta kÃ¼me bazÄ±nda niceleme hatasÄ± daÄŸÄ±lÄ±mÄ±
        st.subheader("Meta KÃ¼me BazÄ±nda Niceleme HatasÄ± DaÄŸÄ±lÄ±mÄ±")
        with st.expander("Bu Grafik Ne Anlama Geliyor?"):
            st.write("""
            Bu grafik, her meta-kÃ¼medeki loglarÄ±n niceleme hata deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir. 
            Box plot grafiÄŸi, her kÃ¼menin medyan, Ã§eyreklikler ve aykÄ±rÄ± deÄŸerlerini gÃ¶sterir. 
            YÃ¼ksek niceleme hatasÄ± deÄŸerleri, daha anormal loglarÄ± gÃ¶sterebilir. KÃ¼meler arasÄ±nda 
            bÃ¼yÃ¼k farklar, farklÄ± davranÄ±ÅŸ modellerini iÅŸaret eder.
            """)
            
            if 'quantization_error' in df_meta.columns:
                fig = px.box(
                    df_meta,
                    x='meta_cluster',
                    y='quantization_error',
                    title='Meta KÃ¼me BazÄ±nda Niceleme HatasÄ± DaÄŸÄ±lÄ±mÄ±',
                    labels={'meta_cluster': 'Meta KÃ¼me', 'quantization_error': 'Niceleme HatasÄ±'},
                    color='meta_cluster'
                )
                st.plotly_chart(fig)
            else:
                st.warning("Niceleme hatasÄ± sÃ¼tunu bulunamadÄ±.")
        
        # Meta kÃ¼me bazÄ±nda log sayÄ±sÄ± grafiÄŸi
        st.subheader("Meta KÃ¼me BazÄ±nda Log SayÄ±sÄ±")
        with st.expander("Bu Grafik Ne Anlama Geliyor?"):
            st.write("""
            Bu Ã§ubuk grafik, her meta-kÃ¼medeki log sayÄ±sÄ±nÄ± gÃ¶sterir. Daha yÃ¼ksek Ã§ubuklar, 
            daha yaygÄ±n davranÄ±ÅŸ modellerini temsil eder. Ã–rneÄŸin, Meta Cluster 0'da Ã§ok sayÄ±da log varsa, 
            bu kÃ¼me sistemdeki baskÄ±n bir davranÄ±ÅŸÄ± gÃ¶sterebilir.
            """)
        
        cluster_counts = df_meta['meta_cluster'].value_counts().reset_index()
        cluster_counts.columns = ['Meta KÃ¼me', 'Log SayÄ±sÄ±']
        
        fig = px.bar(
            cluster_counts,
            x='Meta KÃ¼me',
            y='Log SayÄ±sÄ±',
            title='Meta KÃ¼me BazÄ±nda Log SayÄ±sÄ±'
        )
        st.plotly_chart(fig)
        
        # GeliÅŸmiÅŸ GÃ¶rselleÅŸtirme SeÃ§enekleri
        st.markdown("---")
        st.markdown("### ğŸ¨ GeliÅŸmiÅŸ GÃ¶rselleÅŸtirme SeÃ§enekleri")
        
        visualization_choice = st.selectbox(
            "GÃ¶rselleÅŸtirme TÃ¼rÃ¼ SeÃ§in (Temel Analizler)",
            [
                "Standart Meta KÃ¼meleme (YukarÄ±daki)",
                "1. Karar SÄ±nÄ±rlarÄ±",
                "2. BÃ¼yÃ¼k Noktalar + KalÄ±n KenarlÄ±k", 
                "3. KÃ¼me BaÅŸÄ±na AyrÄ± Subplotlar",
                "4. Etiket FarklarÄ± Analizi",
                "5. Konveks Hull SÄ±nÄ±rlarÄ±",
                "6. KapsamlÄ± KarÅŸÄ±laÅŸtÄ±rma (Hepsi)"
            ],
            help="KÃ¼me sÄ±nÄ±rlarÄ±nÄ± ve farklarÄ±nÄ± gÃ¶rmek iÃ§in farklÄ± gÃ¶rselleÅŸtirme yÃ¶ntemleri",
            key="viz_choice_basic"
        )
        
        if visualization_choice != "Standart Meta KÃ¼meleme (YukarÄ±daki)":
            # Advanced visualizations import
            try:
                from advanced_visualizations import (
                    create_decision_boundary_plot,
                    create_large_points_plot, 
                    create_separate_clusters_plot,
                    create_label_differences_plot,
                    create_convex_hull_plot,
                    create_comprehensive_comparison_plot
                )
                
                # Veri hazÄ±rlÄ±k - Temel analizler iÃ§in SOM ve Meta kÃ¼meleme karÅŸÄ±laÅŸtÄ±rmasÄ±
                if 'X' in st.session_state and st.session_state.X is not None:
                    X_viz = st.session_state.X
                    
                    # SOM etiketleri (BMU bazÄ±nda)
                    if 'bmu_x' in df_meta.columns and 'bmu_y' in df_meta.columns:
                        grid_size = st.session_state.som.get_weights().shape[0]
                        som_labels_viz = df_meta['bmu_x'].values * grid_size + df_meta['bmu_y'].values
                    else:
                        st.error("BMU koordinatlarÄ± bulunamadÄ±!")
                        return
                    
                    # Meta kÃ¼meleme etiketleri
                    meta_labels_viz = df_meta['meta_cluster'].values
                    
                    # NaN kontrol ve temizleme
                    if np.any(np.isnan(X_viz)) or np.any(np.isinf(X_viz)):
                        finite_mask = np.all(np.isfinite(X_viz), axis=1)
                        X_viz = X_viz[finite_mask]
                        som_labels_viz = som_labels_viz[finite_mask]
                        meta_labels_viz = meta_labels_viz[finite_mask]
                    
                    # GÃ¶rselleÅŸtirme seÃ§imi
                    if visualization_choice == "1. Karar SÄ±nÄ±rlarÄ±":
                        st.markdown("#### ğŸ”² Karar SÄ±nÄ±rlarÄ± GÃ¶rselleÅŸtirmesi")
                        st.info("Meta kÃ¼meleme algoritmasÄ±nÄ±n karar bÃ¶lgelerini arka plan renkleri ile gÃ¶sterir")
                        
                        fig = create_decision_boundary_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                    
                    elif visualization_choice == "2. BÃ¼yÃ¼k Noktalar + KalÄ±n KenarlÄ±k":
                        st.markdown("#### ğŸ”µ BÃ¼yÃ¼k Noktalar GÃ¶rselleÅŸtirmesi")
                        st.info("Daha net kÃ¼me aidiyeti gÃ¶sterimi iÃ§in bÃ¼yÃ¼k noktalar ve kalÄ±n kenarlÄ±klar")
                        
                        fig = create_large_points_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                    
                    elif visualization_choice == "3. KÃ¼me BaÅŸÄ±na AyrÄ± Subplotlar":
                        st.markdown("#### ğŸ“Š KÃ¼me BaÅŸÄ±na AyrÄ± GÃ¶rselleÅŸtirme")
                        st.info("Her kÃ¼menin iÃ§sel yapÄ±sÄ±nÄ± ayrÄ± grafikte gÃ¶sterir")
                        
                        fig = create_separate_clusters_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                    
                    elif visualization_choice == "4. Etiket FarklarÄ± Analizi":
                        st.markdown("#### ğŸ” Etiket FarklarÄ± Analizi")
                        st.info("SOM ve Meta kÃ¼meleme arasÄ±nda farklÄ± kÃ¼meye atanan loglarÄ± vurgular")
                        
                        fig = create_label_differences_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                    
                    elif visualization_choice == "5. Konveks Hull SÄ±nÄ±rlarÄ±":
                        st.markdown("#### ğŸ”· Konveks Hull SÄ±nÄ±rlarÄ±")
                        st.info("KÃ¼me sÄ±nÄ±rlarÄ±nÄ± Ã§izgilerle gÃ¶sterir")
                        
                        fig = create_convex_hull_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                    
                    elif visualization_choice == "6. KapsamlÄ± KarÅŸÄ±laÅŸtÄ±rma (Hepsi)":
                        st.markdown("#### ğŸ¯ KapsamlÄ± KarÅŸÄ±laÅŸtÄ±rma")
                        st.info("TÃ¼m gÃ¶rselleÅŸtirme yÃ¶ntemlerini tek seferde gÃ¶sterir")
                        
                        fig = create_comprehensive_comparison_plot(X_viz, som_labels_viz, meta_labels_viz)
                        if fig:
                            st.pyplot(fig)
                            
                        # Ä°lave analiz bilgileri
                        with st.expander("DetaylÄ± Analiz Bilgileri"):
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("Toplam Log SayÄ±sÄ±", len(som_labels_viz))
                                st.metric("SOM KÃ¼me SayÄ±sÄ±", len(np.unique(som_labels_viz)))
                                
                            with col2:
                                st.metric("Meta KÃ¼me SayÄ±sÄ±", len(np.unique(meta_labels_viz)))
                                same_labels = np.sum(som_labels_viz == meta_labels_viz)
                                st.metric("Etiket BenzerliÄŸi", f"{same_labels/len(som_labels_viz):.1%}")
                                
                            with col3:
                                som_std = np.std(pd.Series(som_labels_viz).value_counts())
                                meta_std = np.std(pd.Series(meta_labels_viz).value_counts())
                                st.metric("SOM KÃ¼me Boyutu Std", f"{som_std:.1f}")
                                st.metric("Meta KÃ¼me Boyutu Std", f"{meta_std:.1f}")
                else:
                    st.warning("X veri seti bulunamadÄ±. Ã–nce SOM eÄŸitimi yapÄ±lmalÄ±.")
            
            except ImportError as e:
                st.error(f"GeliÅŸmiÅŸ gÃ¶rselleÅŸtirme modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")
                st.info("advanced_visualizations.py dosyasÄ±nÄ±n mevcut olduÄŸundan emin olun")
            
            except Exception as e:
                st.error(f"GÃ¶rselleÅŸtirme hatasÄ±: {str(e)}")
                st.info("Standart meta kÃ¼melemeyi kullanÄ±n")
    
    except Exception as e:
        st.error(f"Meta kÃ¼meleme sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}")
        import traceback
        st.warning(traceback.format_exc())

def handle_neuron_details():
    st.subheader("NÃ¶ron DetaylarÄ±")
    with st.expander("Bu BÃ¶lÃ¼m Ne Anlama Geliyor?"):
        st.write("""
        Bu bÃ¶lÃ¼m, seÃ§ilen bir SOM nÃ¶ronundaki loglarÄ±n detaylarÄ±nÄ± gÃ¶sterir. 
        Bir nÃ¶ron seÃ§erek, o nÃ¶rona atanan loglarÄ±n Ã¶zelliklerini (Ã¶rneÄŸin, engellenmiÅŸ istek sayÄ±sÄ±, en sÄ±k URI) 
        inceleyebilirsiniz. Vurgulanan kÄ±rmÄ±zÄ± 'X', seÃ§ilen nÃ¶ronun Ä±zgaradaki konumunu gÃ¶sterir.
        """)
    
    if 'summary_df' not in st.session_state or st.session_state.summary_df is None:
        create_summary_table()
    
    if 'summary_df' in st.session_state and st.session_state.summary_df is not None:
        selected_neuron = st.selectbox("Bir nÃ¶ron seÃ§in", options=st.session_state.summary_df['NÃ¶ron'])
        bmu_x, bmu_y = map(int, selected_neuron.strip('()').split(','))
        neuron_group = st.session_state.df[(st.session_state.df['bmu_x'] == bmu_x) & (st.session_state.df['bmu_y'] == bmu_y)]
        
        # Hover sÃ¼tunlarÄ±nÄ± belirle
        hover_columns = ['bmu_x', 'bmu_y', 'quantization_error']
        
        # URI sÃ¼tunu
        uri_cols = ['transaction.request.uri', 'request.uri', 'request_uri']
        uri_col = next((col for col in uri_cols if col in st.session_state.df.columns), None)
        if uri_col:
            hover_columns.append(uri_col)
        
        # Engellenme sÃ¼tunu
        interrupted_cols = ['transaction.is_interrupted', 'is_interrupted']
        interrupted_col = next((col for col in interrupted_cols if col in st.session_state.df.columns), None)
        if interrupted_col:
            hover_columns.append(interrupted_col)
        
        # Client port sÃ¼tunu
        port_cols = ['transaction.client_port', 'client_port']
        port_col = next((col for col in port_cols if col in st.session_state.df.columns), None)
        if port_col:
            hover_columns.append(port_col)
        
        # Scatter plot
        fig = px.scatter(
            st.session_state.df,
            x='bmu_x',
            y='bmu_y',
            color='quantization_error',
            hover_data=hover_columns,
            title='SOM IzgarasÄ±ndaki Log DaÄŸÄ±lÄ±mÄ± (SeÃ§ilen NÃ¶ron VurgulandÄ±)',
            color_continuous_scale='Viridis'
        )
        fig.add_trace(
            go.Scatter(
                x=[bmu_x],
                y=[bmu_y],
                mode='markers',
                marker=dict(size=15, color='red', symbol='x'),
                name='SeÃ§ilen NÃ¶ron'
            )
        )
        st.plotly_chart(fig)
        
        # SeÃ§ilen nÃ¶rondaki loglarÄ± gÃ¶ster
        st.write(f"**NÃ¶ron ({bmu_x},{bmu_y}) DetaylarÄ±:**")
        st.write(f"Bu nÃ¶ronda toplam {len(neuron_group)} log bulundu.")
        
        # En sÄ±k URI
        if uri_col and len(neuron_group) > 0:
            uri_counts = neuron_group[uri_col].value_counts().head(5)
            st.write("**En SÄ±k URI'ler:**")
            for uri, count in uri_counts.items():
                st.write(f"- {uri}: {count} kez")
        
        # Ortalama niceleme hatasÄ±
        avg_qe = neuron_group['quantization_error'].mean() if 'quantization_error' in neuron_group.columns else 0
        st.write(f"**Ortalama Niceleme HatasÄ±:** {avg_qe:.4f}")
        
        # Engellenme oranÄ±
        if interrupted_col and len(neuron_group) > 0:
            block_rate = neuron_group[interrupted_col].mean()
            st.write(f"**Engellenme OranÄ±:** {block_rate:.2%}")
        
        # Ã–rnek loglarÄ± gÃ¶ster
        st.write("**Ã–rnek Loglar:**")
        st.dataframe(neuron_group.head(10))
    else:
        st.warning("HenÃ¼z nÃ¶ron analizi yapÄ±lamadÄ±. Ã–nce SOM eÄŸitimi tamamlanmalÄ±.")

def handle_anomaly_detection():
    st.subheader("Anomali Tespiti")
    with st.expander("Anomali Tespiti Nedir?"):
        st.write("""
        Bu bÃ¶lÃ¼m, SOM modelini kullanarak potansiyel anomalileri tespit eder.
        Niceleme hatasÄ± yÃ¼ksek olan loglar, veri setindeki genel kalÄ±plara uymayan 'aykÄ±rÄ±' 
        kayÄ±tlar olarak kabul edilir. Bunlar, potansiyel gÃ¼venlik tehditleri veya sistem anormallikleri olabilir.
        """)
    
    # Anomali eÅŸiÄŸi iÃ§in kullanÄ±cÄ± inputu
    percentile = st.slider("Niceleme HatasÄ± EÅŸik YÃ¼zdesi", 90, 99, 95, 
                          help="Belirtilen yÃ¼zdelik dilimin Ã¼zerindeki niceleme hatasÄ±na sahip loglarÄ± anomali olarak iÅŸaretle")
    
    if st.session_state.df is not None and 'quantization_error' in st.session_state.df.columns:
        # Belirtilen eÅŸiÄŸe gÃ¶re anomalileri tespit et
        threshold = np.percentile(st.session_state.df['quantization_error'], percentile)
        anomalies = st.session_state.df[st.session_state.df['quantization_error'] > threshold].copy()
        
        st.write(f"**Tespit Edilen Anomali SayÄ±sÄ±:** {len(anomalies)}")
        st.write(f"**Niceleme HatasÄ± EÅŸiÄŸi:** {threshold:.4f}")
        
        # Anomalilerle ilgili daha detaylÄ± bilgi
        if len(anomalies) > 0:
            # GÃ¶sterilecek sÃ¼tunlarÄ± belirle
            cols_to_display = ['bmu_x', 'bmu_y', 'quantization_error']
            
            # URI sÃ¼tunu
            uri_cols = ['transaction.request.uri', 'request.uri', 'request_uri']
            uri_col = next((col for col in uri_cols if col in anomalies.columns), None)
            if uri_col:
                cols_to_display.append(uri_col)
            
            # Client port sÃ¼tunu
            port_cols = ['transaction.client_port', 'client_port']
            port_col = next((col for col in port_cols if col in anomalies.columns), None)
            if port_col:
                cols_to_display.append(port_col)
                
            # Engellenme sÃ¼tunu
            interrupted_cols = ['transaction.is_interrupted', 'is_interrupted']
            interrupted_col = next((col for col in interrupted_cols if col in anomalies.columns), None)
            if interrupted_col:
                cols_to_display.append(interrupted_col)
            
            # Anomalileri gÃ¶ster
            st.dataframe(anomalies[cols_to_display].sort_values('quantization_error', ascending=False))
            
            # Anomalilerin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
            fig = px.scatter(
                anomalies,
                x='bmu_x',
                y='bmu_y',
                color='quantization_error',
                hover_data=cols_to_display,
                title='SOM Izgara Anomali DaÄŸÄ±lÄ±mÄ±',
                color_continuous_scale='Reds'
            )
            st.plotly_chart(fig)
            
            # Anomalilerin URI daÄŸÄ±lÄ±mÄ±
            if uri_col:
                uri_counts = anomalies[uri_col].value_counts().head(10)
                fig = px.pie(
                    values=uri_counts.values,
                    names=uri_counts.index,
                    title='Anomali URI\'lerin DaÄŸÄ±lÄ±mÄ±'
                )
                st.plotly_chart(fig)
                
                st.write("#### En SÄ±k Anomali URI'ler:")
                for uri, count in uri_counts.items():
                    st.write(f"- {uri}: {count} kez")
        else:
            st.info("SeÃ§ilen eÅŸiÄŸe gÃ¶re anomali tespit edilemedi. EÅŸik deÄŸerini dÃ¼ÅŸÃ¼rebilirsiniz.")
    else:
        st.warning("Veri yÃ¼klenmiÅŸ ve SOM eÄŸitilmiÅŸ olmalÄ±dÄ±r.")

def show_som_validation():
    st.subheader("SOM Model DoÄŸrulama")
    
    if st.session_state.som is None or st.session_state.X is None:
        st.warning("SOM modeli henÃ¼z eÄŸitilmemiÅŸ.")
        return
    
    with st.expander("SOM DoÄŸrulama Nedir?"):
        st.write("""
        1. **Niceleme HatasÄ±**: Her log kaydÄ±nÄ±n SOM'daki en iyi eÅŸleÅŸen birimle (BMU) arasÄ±ndaki mesafeyi Ã¶lÃ§er. 
           DÃ¼ÅŸÃ¼k deÄŸerler, verinin SOM tarafÄ±ndan iyi temsil edildiÄŸini gÃ¶sterir.
           
        2. **Topolojik Hata**: Bir veri noktasÄ±nÄ±n BMU'su ve ikinci en iyi eÅŸleÅŸen birimi SOM Ä±zgarasÄ±nda komÅŸu deÄŸilse 
           bir hata oluÅŸur. Bu Ã¶lÃ§Ã¼m, SOM'un giriÅŸ verisinin topolojisini ne kadar iyi koruduÄŸunu gÃ¶sterir.
           
        3. **SilÃ¼et Skoru**: KÃ¼melerin ne kadar iyi ayrÄ±ldÄ±ÄŸÄ±nÄ± Ã¶lÃ§er. YÃ¼ksek deÄŸerler (1'e yakÄ±n), 
           kÃ¼melerin iyi tanÄ±mlandÄ±ÄŸÄ±nÄ± gÃ¶sterir.
        """)
    
    # SOM model performansÄ±nÄ± hesapla
    try:
        # Niceleme hatasÄ± - doÄŸrudan df'den alÄ±yoruz, Ã§Ã¼nkÃ¼ Ã¶nceden hesaplanmÄ±ÅŸ
        if 'quantization_error' in st.session_state.df.columns:
            total_qe = st.session_state.df['quantization_error'].mean()
        else:
            total_qe = "HesaplanamadÄ±"
        
        # Topolojik hata
        # Not: SOM ve X Ã¶zellikleri uyumsuzsa bu kÄ±smÄ± atlÄ±yoruz
        try:
            # Ã‡ok fazla veri noktasÄ± varsa Ã¶rnekleme yap
            if len(st.session_state.X) > 1000:
                indices = np.random.choice(len(st.session_state.X), 1000, replace=False)
                sample_X = st.session_state.X[indices]
                topographic_error = calculate_topographic_error(st.session_state.som, sample_X)
            else:
                topographic_error = calculate_topographic_error(st.session_state.som, st.session_state.X)
        except:
            topographic_error = "HesaplanamadÄ±"
            
        # SilÃ¼et skoru hesapla (kÃ¼meleme yapÄ±lmÄ±ÅŸsa)
        silhouette = "N/A"
        try:
            if 'df_meta' in st.session_state and st.session_state.df_meta is not None:
                if 'meta_cluster' in st.session_state.df_meta.columns:
                    labels = st.session_state.df_meta['meta_cluster'].values
                    # SilÃ¼et skoru en az 2 kÃ¼me ve her kÃ¼mede en az 1 eleman gerektirir
                    if len(np.unique(labels)) >= 2:
                        from sklearn.metrics import silhouette_score
                        silhouette = silhouette_score(st.session_state.X, labels)
        except:
            silhouette = "HesaplanamadÄ±"
        
        # SonuÃ§larÄ± gÃ¶ster
        metrics = {
            "Metrik": ["Niceleme HatasÄ±", "Topolojik Hata", "SilÃ¼et Skoru"],
            "DeÄŸer": [f"{total_qe:.4f}" if isinstance(total_qe, float) else total_qe, 
                    f"{topographic_error:.4f}" if isinstance(topographic_error, float) else topographic_error, 
                    f"{silhouette:.4f}" if isinstance(silhouette, float) else silhouette],
            "Yorum": [
                "DÃ¼ÅŸÃ¼k deÄŸer iyi (0'a yakÄ±n)",
                "DÃ¼ÅŸÃ¼k deÄŸer iyi (0'a yakÄ±n)",
                "YÃ¼ksek deÄŸer iyi (1'e yakÄ±n)"
            ]
        }
        st.table(pd.DataFrame(metrics))
        
        # Yorumlama
        st.write("#### SonuÃ§larÄ±n YorumlanmasÄ±")
        
        if isinstance(total_qe, float):
            if total_qe < 0.1:
                st.success("Niceleme HatasÄ± Ã§ok dÃ¼ÅŸÃ¼k. SOM, veriyi Ã§ok iyi temsil ediyor.")
            elif total_qe < 0.3:
                st.info("Niceleme HatasÄ± makul dÃ¼zeyde. SOM, veriyi yeterince iyi temsil ediyor.")
            else:
                st.warning("Niceleme HatasÄ± yÃ¼ksek. SOM parametrelerini ayarlamak veya eÄŸitim sÃ¼resini uzatmak faydalÄ± olabilir.")
            
        if isinstance(topographic_error, float):
            if topographic_error < 0.05:
                st.success("Topolojik Hata Ã§ok dÃ¼ÅŸÃ¼k. SOM, veri topolojisini mÃ¼kemmel koruyor.")
            elif topographic_error < 0.1:
                st.info("Topolojik Hata makul dÃ¼zeyde. SOM, veri topolojisini iyi koruyor.")
            else:
                st.warning("Topolojik Hata yÃ¼ksek. SOM Ä±zgara boyutunu arttÄ±rmak faydalÄ± olabilir.")
            
        if isinstance(silhouette, float):
            if silhouette > 0.7:
                st.success("SilÃ¼et Skoru Ã§ok iyi. KÃ¼meler net bir ÅŸekilde ayrÄ±lmÄ±ÅŸ.")
            elif silhouette > 0.5:
                st.info("SilÃ¼et Skoru iyi. KÃ¼meler makul dÃ¼zeyde ayrÄ±lmÄ±ÅŸ.")
            elif silhouette > 0.3:
                st.warning("SilÃ¼et Skoru orta dÃ¼zeyde. KÃ¼me sayÄ±sÄ±nÄ± optimize etmek faydalÄ± olabilir.")
            else:
                st.error("SilÃ¼et Skoru dÃ¼ÅŸÃ¼k. KÃ¼meler iyi ayrÄ±lmamÄ±ÅŸ. FarklÄ± bir kÃ¼me sayÄ±sÄ± deneyin.")
    
    except Exception as e:
        st.error(f"SOM doÄŸrulama hesaplanÄ±rken bir hata oluÅŸtu: {str(e)}")
        import traceback
        st.warning(traceback.format_exc())

def calculate_topographic_error(som, data):
    """Topolojik hata hesaplama"""
    error = 0
    for x in data:
        w1 = som.winner(x)
        w2 = find_second_best_matching_unit(som, x)
        if not are_neighbors(som, w1, w2):
            error += 1
    return error / len(data)

def find_second_best_matching_unit(som, x):
    """Ä°kinci en iyi eÅŸleÅŸen birimi bul"""
    # TÃ¼m nÃ¶ronlar iÃ§in mesafeleri hesapla
    distances = np.zeros((som.get_weights().shape[0], som.get_weights().shape[1]))
    for i in range(som.get_weights().shape[0]):
        for j in range(som.get_weights().shape[1]):
            distances[i, j] = np.linalg.norm(x - som.get_weights()[i, j])
    
    # En iyi eÅŸleÅŸen birimi bul
    best_matching_unit = som.winner(x)
    
    # En iyi eÅŸleÅŸen birimin mesafesini Ã§ok bÃ¼yÃ¼k bir sayÄ± yap
    distances[best_matching_unit] = float('inf')
    
    # Ä°kinci en iyi eÅŸleÅŸen birimi bul
    second_best = np.unravel_index(np.argmin(distances), distances.shape)
    
    return second_best

def are_neighbors(som, w1, w2):
    """Ä°ki nÃ¶ronun komÅŸu olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
    return abs(w1[0] - w2[0]) <= 1 and abs(w1[1] - w2[1]) <= 1

def calculate_silhouette_score(X, labels):
    """SilÃ¼et skoru hesaplama"""
    from sklearn.metrics import silhouette_score
    return silhouette_score(X, labels['bmu_x'] * 100 + labels['bmu_y'])

def show_meta_clustering_validation():
    st.subheader("Meta KÃ¼meleme DoÄŸrulama")
    with st.expander("Meta KÃ¼meleme DoÄŸrulama Nedir?"):
        st.write("""
        Bu bÃ¶lÃ¼m, meta kÃ¼meleme (K-means ile SOM haritasÄ±nÄ± kÃ¼meleme) sonuÃ§larÄ±nÄ±n kalitesini deÄŸerlendirir:
        
        1. **SilÃ¼et Skoru**: KÃ¼melerin ne kadar iyi ayrÄ±ldÄ±ÄŸÄ±nÄ± ve iÃ§lerindeki verilerin ne kadar benzer olduÄŸunu Ã¶lÃ§er.
           DeÄŸerler -1 ile 1 arasÄ±nda deÄŸiÅŸir; yÃ¼ksek deÄŸerler (1'e yakÄ±n) daha iyi kÃ¼meleme kalitesini gÃ¶sterir.
           
        2. **Calinski-Harabasz Skoru**: KÃ¼me kompaktlÄ±ÄŸÄ±nÄ± ve ayrÄ±lÄ±ÄŸÄ±nÄ± deÄŸerlendirir. 
           YÃ¼ksek deÄŸerler, kÃ¼melerin iÃ§lerinde kompakt ve birbirlerinden ayrÄ±k olduÄŸunu gÃ¶sterir.
           
        3. **Davies-Bouldin Skoru**: KÃ¼meler arasÄ± benzerliÄŸi ve kÃ¼me iÃ§i benzerliÄŸi Ã¶lÃ§er.
           DÃ¼ÅŸÃ¼k deÄŸerler, daha iyi kÃ¼meleme kalitesini gÃ¶sterir.
        """)
    
    if (st.session_state.som is None or 
        'meta_clusters' not in st.session_state or 
        st.session_state.meta_clusters is None):
        st.warning("Meta kÃ¼meleme henÃ¼z yapÄ±lmamÄ±ÅŸ. Ã–nce Meta KÃ¼meleme Analizi bÃ¶lÃ¼mÃ¼ndeki 'Meta KÃ¼me SayÄ±sÄ±' belirleyip Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return
    
    try:
        # SOM aÄŸÄ±rlÄ±klarÄ± kontrol et
        if 'som_weights_reshaped' not in st.session_state:
            st.warning("SOM aÄŸÄ±rlÄ±klarÄ± bulunamadÄ±. LÃ¼tfen Ã¶nce Meta KÃ¼meleme analizini Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return
        
        # Meta kÃ¼meleme etiketlerini al
        meta_clusters = st.session_state.meta_clusters
        weights = st.session_state.som_weights_reshaped
        
        # Metrikleri hesapla
        if len(np.unique(meta_clusters)) >= 2:  # En az 2 kÃ¼me olmalÄ±
            try:
                from sklearn.metrics import silhouette_score
                
                # Silhouette skoru hesaplamasÄ± iÃ§in ek kontroller
                unique_clusters = np.unique(meta_clusters)
                min_samples_per_cluster = min([np.sum(meta_clusters == c) for c in unique_clusters])
                
                if min_samples_per_cluster >= 1 and len(unique_clusters) >= 2:
                    silhouette = silhouette_score(weights, meta_clusters)
                else:
                    silhouette = "HesaplanamadÄ± (BazÄ± kÃ¼meler tek elemanlÄ± veya kÃ¼me sayÄ±sÄ± yetersiz)"
            except Exception as e:
                silhouette = f"HesaplanamadÄ±: {str(e)}"
                
            try:
                from sklearn.metrics import calinski_harabasz_score
                calinski = calinski_harabasz_score(weights, meta_clusters)
            except:
                calinski = "HesaplanamadÄ±"
                
            try:
                from sklearn.metrics import davies_bouldin_score
                davies = davies_bouldin_score(weights, meta_clusters)
            except:
                davies = "HesaplanamadÄ±"
                
            # SonuÃ§larÄ± gÃ¶ster
            metrics = {
                "Metrik": ["SilÃ¼et Skoru", "Calinski-Harabasz Skoru", "Davies-Bouldin Skoru"],
                "DeÄŸer": [
                    f"{silhouette:.4f}" if isinstance(silhouette, float) else silhouette,
                    f"{calinski:.2f}" if isinstance(calinski, float) else calinski,
                    f"{davies:.4f}" if isinstance(davies, float) else davies
                ],
                "Yorumlama": [
                    "YÃ¼ksek deÄŸer iyi (-1 ile 1 arasÄ±, 1'e yakÄ±n = iyi)",
                    "YÃ¼ksek deÄŸer iyi (baÄŸÄ±l Ã¶lÃ§Ã¼)",
                    "DÃ¼ÅŸÃ¼k deÄŸer iyi (0'a yakÄ±n = iyi)"
                ]
            }
            st.table(pd.DataFrame(metrics))
            
            # Yorumlama
            if isinstance(silhouette, float):
                st.subheader("SilÃ¼et Skoru Yorumu")
                if silhouette > 0.7:
                    st.success(f"MÃ¼kemmel kÃ¼meleme kalitesi ({silhouette:.4f})")
                elif silhouette > 0.5:
                    st.info(f"Ä°yi kÃ¼meleme kalitesi ({silhouette:.4f})")
                elif silhouette > 0.3:
                    st.warning(f"Orta dÃ¼zeyde kÃ¼meleme kalitesi ({silhouette:.4f})")
                else:
                    st.error(f"ZayÄ±f kÃ¼meleme kalitesi ({silhouette:.4f}) - FarklÄ± bir kÃ¼me sayÄ±sÄ± deneyin")
                    
            # GÃ¶rselleÅŸtirme
            if st.session_state.df_meta is not None:
                st.subheader("Her KÃ¼meden Log Ã–rnekleri")
                
                unique_clusters = sorted(st.session_state.df_meta['meta_cluster'].unique())
                selected_cluster = st.selectbox("KÃ¼me", options=unique_clusters)
                
                cluster_samples = st.session_state.df_meta[st.session_state.df_meta['meta_cluster'] == selected_cluster]
                
                if len(cluster_samples) > 0:
                    st.write(f"KÃ¼me {selected_cluster}'de {len(cluster_samples)} log bulundu.")
                    
                    # GÃ¶rÃ¼ntÃ¼lenecek sÃ¼tunlarÄ± belirle
                    display_cols = ['bmu_x', 'bmu_y', 'quantization_error']
                    
                    # URI ve diÄŸer Ã¶nemli sÃ¼tunlarÄ± ekle
                    uri_cols = ['transaction.request.uri', 'request.uri', 'request_uri']
                    uri_col = next((col for col in uri_cols if col in cluster_samples.columns), None)
                    if uri_col:
                        display_cols.append(uri_col)
                    
                    # Engellenme durumu
                    interrupted_cols = ['transaction.is_interrupted', 'is_interrupted']
                    interrupted_col = next((col for col in interrupted_cols if col in cluster_samples.columns), None)
                    if interrupted_col:
                        display_cols.append(interrupted_col)
                    
                    st.dataframe(cluster_samples[display_cols].head(10))
                    
                    # KÃ¼me iÃ§indeki en sÄ±k URI'ler
                    if uri_col:
                        uri_counts = cluster_samples[uri_col].value_counts().head(5)
                        st.write("#### Bu KÃ¼medeki En SÄ±k URI'ler:")
                        for uri, count in uri_counts.items():
                            st.write(f"- {uri}: {count} adet")
                    
                    # KÃ¼menin karakteristiÄŸi
                    st.write("#### KÃ¼me KarakteristiÄŸi:")
                    
                    stats = {
                        "Niceleme HatasÄ± (Ortalama)": f"{cluster_samples['quantization_error'].mean():.4f}",
                        "Log SayÄ±sÄ±": f"{len(cluster_samples)}"
                    }
                    
                    if interrupted_col:
                        stats["Engellenme OranÄ±"] = f"{cluster_samples[interrupted_col].mean():.2%}"
                    
                    stats_df = pd.DataFrame(list(stats.items()), columns=["Metrik", "DeÄŸer"])
                    st.table(stats_df)
                else:
                    st.warning(f"KÃ¼me {selected_cluster} iÃ§in log bulunamadÄ±.")
            
        else:
            st.error("En az 2 meta kÃ¼me olmalÄ±dÄ±r. Daha yÃ¼ksek bir kÃ¼me sayÄ±sÄ± belirleyin.")
    
    except Exception as e:
        st.error(f"Meta kÃ¼meleme doÄŸrulama hesaplanÄ±rken bir hata oluÅŸtu: {str(e)}")
        import traceback
        st.warning(traceback.format_exc())

def show_advanced_analysis():
    if st.session_state.som is None:
        st.info("Ã–nce bir SOM modeli eÄŸitmeniz gerekiyor.")
        return
    
    try:
        # Sekmeleri oluÅŸtur
        tabs = st.tabs([
            "Optimal KÃ¼me SayÄ±sÄ±",
            "KÃ¼meleme AlgoritmalarÄ±",
            "KÃ¼meleme Stabilitesi",
            "Boyut Ä°ndirgeme",
            "Ã‡apraz DoÄŸrulama",
            "PDF Rapor"
        ])
        
        # Tab 1: Optimal KÃ¼me SayÄ±sÄ±
        with tabs[0]:
            st.write("""
            ### Optimal KÃ¼me SayÄ±sÄ± Analizi
            Bu analiz, meta kÃ¼meleme iÃ§in en uygun kÃ¼me sayÄ±sÄ±nÄ± (K) belirler. 
            Dirsek YÃ¶ntemi, SilÃ¼et Skoru, Calinski-Harabasz Indeksi ve 
            Davies-Bouldin Indeksi gibi Ã§eÅŸitli metrikler kullanÄ±lÄ±r.
            """)
            
            # KullanÄ±cÄ±dan max_k deÄŸerini al
            max_k = st.slider("DeÄŸerlendirilecek maksimum kÃ¼me sayÄ±sÄ±", 5, 30, 15, key="max_k_slider")
            
            # Daha Ã¶nce hesaplanmamÄ±ÅŸsa yeni bir analiz yap
            if st.button("Optimal K Analizi Yap"):
                from advanced_clustering import find_optimal_k
                
                with st.spinner("Optimal K deÄŸeri hesaplanÄ±yor..."):
                    st.session_state.optimal_k_results = find_optimal_k(max_k=max_k)
                    
                    if st.session_state.optimal_k_results:
                        st.session_state.optimal_k = st.session_state.optimal_k_results.get('optimal_k')
            
            # SonuÃ§larÄ± gÃ¶ster
            if 'optimal_k_results' in st.session_state and st.session_state.optimal_k_results:
                results = st.session_state.optimal_k_results
                
                st.success(f"Ã–nerilen K deÄŸeri: **{results.get('optimal_k')}**")
                
                col1, col2 = st.columns([1, 1])
                with col1:
                    metrics_table = {
                        "Metrik": ["Dirsek YÃ¶ntemi", "SilÃ¼et Skoru", "Calinski-Harabasz", "Davies-Bouldin"],
                        "Optimal K": [
                            results.get('elbow_k'),
                            results.get('silhouette_k'),
                            results.get('calinski_k'),
                            results.get('davies_k')
                        ]
                    }
                    st.table(pd.DataFrame(metrics_table))
                
                if 'visualization' in results or 'visualization_base64' in results:
                    vis_key = 'visualization_base64' if 'visualization_base64' in results else 'visualization'
                    show_matplotlib_figure(results[vis_key])
        
        # Tab 2: KÃ¼meleme AlgoritmalarÄ±
        with tabs[1]:
            st.write("""
            ### KÃ¼meleme AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±
            FarklÄ± kÃ¼meleme algoritmalarÄ±nÄ± (K-means, HiyerarÅŸik KÃ¼meleme, DBSCAN, HDBSCAN) 
            karÅŸÄ±laÅŸtÄ±rÄ±r. SilÃ¼et skoru, Calinski-Harabasz ve Davies-Bouldin metrikleri 
            kullanÄ±larak performanslarÄ± Ã¶lÃ§Ã¼lÃ¼r.
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                selected_k = st.slider(
                    "KÃ¼me SayÄ±sÄ±", 
                    2, 15, 
                    st.session_state.optimal_k if 'optimal_k' in st.session_state and st.session_state.optimal_k else 5
                )
            
            st.subheader("DBSCAN Parametreleri")
            col1, col2 = st.columns(2)
            with col1:
                use_custom_eps = st.checkbox("Ã–zel Epsilon Kullan", False)
                if use_custom_eps:
                    dbscan_eps = st.slider("DBSCAN Epsilon", 0.01, 2.0, 0.5, 0.01)
                else:
                    dbscan_eps = None
            
            with col2:
                dbscan_min_samples = st.slider("DBSCAN Min Samples", 2, 20, 5)
            
            if st.button("AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±r", key="compare_algo_button"):
                from advanced_clustering import compare_clustering_algorithms
                
                with st.spinner("KÃ¼meleme algoritmalarÄ± karÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor..."):
                    st.session_state.alternative_clustering_results = compare_clustering_algorithms(
                        n_clusters=selected_k,
                        dbscan_eps=dbscan_eps,
                        dbscan_min_samples=dbscan_min_samples
                    )
            
            # Ã–nceden hesaplanmÄ±ÅŸ sonuÃ§larÄ± gÃ¶ster
            if 'alternative_clustering_results' in st.session_state and st.session_state.alternative_clustering_results is not None:
                comparison_results = st.session_state.alternative_clustering_results
                
                if 'metrics' in comparison_results:
                    st.subheader("KÃ¼meleme AlgoritmalarÄ± Metrikler KarÅŸÄ±laÅŸtÄ±rmasÄ±")
                    st.table(comparison_results['metrics'])
                    
                    if 'visualizations' in comparison_results:
                        if 'Metrikler' in comparison_results['visualizations']:
                            show_matplotlib_figure(comparison_results['visualizations']['Metrikler'])
                    
                    st.subheader("Her Algoritma iÃ§in KÃ¼meleme GÃ¶rselleÅŸtirmesi")
                    
                    if 'visualizations' in comparison_results:
                        algo_names = [name for name in comparison_results['visualizations'].keys() if name != 'Metrikler']
                        if algo_names:
                            algo_tabs = st.tabs(algo_names)
                            for i, algo_name in enumerate(algo_names):
                                with algo_tabs[i]:
                                    show_matplotlib_figure(comparison_results['visualizations'][algo_name])
        
        # Tab 3: KÃ¼meleme Stabilitesi
        with tabs[2]:
            st.write("""
            ### KÃ¼meleme Stabilitesi Analizi
            Bu analiz, K-means kÃ¼melemesinin ne kadar tutarlÄ± sonuÃ§lar verdiÄŸini deÄŸerlendirir.
            FarklÄ± baÅŸlangÄ±Ã§ noktalarÄ±yla K-means Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r ve sonuÃ§lar karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
            YÃ¼ksek stabilite skoru, daha gÃ¼venilir kÃ¼meleme demektir.
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                stability_k = st.slider(
                    "Stabilite Analizi iÃ§in K", 
                    2, 15, 
                    st.session_state.optimal_k if 'optimal_k' in st.session_state and st.session_state.optimal_k else 5
                )
            with col2:
                n_runs = st.slider(
                    "Tekrar SayÄ±sÄ±", 
                    3, 10, 5
                )
            
            if st.button("Stabilite Analizi Yap", key="stability_button"):
                st.session_state.stability_results = None  # Ã–nceki sonuÃ§larÄ± temizle
                from advanced_clustering import analyze_clustering_stability
                
                with st.spinner("KÃ¼meleme stabilitesi deÄŸerlendiriliyor..."):
                    st.session_state.stability_results = analyze_clustering_stability(n_runs=n_runs, n_clusters=stability_k)
            
            if 'stability_results' in st.session_state and st.session_state.stability_results is not None:
                stability_results = st.session_state.stability_results
                
                st.success(f"Ortalama Stabilite Skoru: **{stability_results.get('stability_score', 0):.4f}**")
                st.info("(Skor 1'e yaklaÅŸtÄ±kÃ§a daha stabil kÃ¼meleme anlamÄ±na gelir)")
                
                if 'visualization' in stability_results:
                    show_matplotlib_figure(stability_results['visualization'])
        
        # Tab 4: Boyut Ä°ndirgeme
        with tabs[3]:
            st.write("""
            ### Boyut Ä°ndirgeme Analizi
            PCA, t-SNE ve UMAP gibi farklÄ± boyut indirgeme teknikleriyle SOM nÃ¶ronlarÄ±nÄ±n
            dÃ¼ÅŸÃ¼k boyutlu gÃ¶rselleÅŸtirmesini yapar. Bu, nÃ¶ron yapÄ±sÄ±nÄ± daha iyi anlamanÄ±za yardÄ±mcÄ± olur.
            """)
            
            dr_k = st.slider(
                "Boyut Ä°ndirgeme iÃ§in K", 
                2, 15, 
                st.session_state.optimal_k if 'optimal_k' in st.session_state and st.session_state.optimal_k else 5
            )
            
            if st.button("Boyut Ä°ndirgeme Analizi Yap"):
                from advanced_clustering import dimensionality_reduction_analysis
                
                with st.spinner("Boyut indirgeme analizi yapÄ±lÄ±yor..."):
                    st.session_state.dimensionality_reduction_results = dimensionality_reduction_analysis(n_clusters=dr_k)
            
            if 'dimensionality_reduction_results' in st.session_state and st.session_state.dimensionality_reduction_results is not None:
                dr_results = st.session_state.dimensionality_reduction_results
                
                method_names = list(dr_results.keys())
                if method_names:
                    method_tabs = st.tabs(method_names)
                    for i, method_name in enumerate(method_names):
                        with method_tabs[i]:
                            show_matplotlib_figure(dr_results[method_name])
        
        # Tab 5: Ã‡apraz DoÄŸrulama
        with tabs[4]:
            st.write("""
            ### Ã‡apraz DoÄŸrulama Analizi
            Bu analiz, verinin farklÄ± alt kÃ¼meleri Ã¼zerinde kÃ¼meleme yaparak sonuÃ§larÄ±n
            tutarlÄ±lÄ±ÄŸÄ±nÄ± deÄŸerlendirir. YÃ¼ksek silÃ¼et skorlarÄ±, gÃ¼venilir kÃ¼meleme gÃ¶stergesidir.
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                cv_k = st.slider(
                    "Ã‡apraz DoÄŸrulama iÃ§in K", 
                    2, 15, 
                    st.session_state.optimal_k if 'optimal_k' in st.session_state and st.session_state.optimal_k else 5
                )
            with col2:
                n_splits = st.slider(
                    "Ã‡apraz DoÄŸrulama ParÃ§a SayÄ±sÄ±", 
                    3, 10, 5
                )
            
            if st.button("Ã‡apraz DoÄŸrulama Yap", key="cv_button"):
                st.session_state.cross_validation_results = None  # Ã–nceki sonuÃ§larÄ± temizle
                from advanced_clustering import perform_cross_validation_clustering
                
                with st.spinner("Ã‡apraz doÄŸrulama analizi yapÄ±lÄ±yor..."):
                    st.session_state.cross_validation_results = perform_cross_validation_clustering(n_splits=n_splits, n_clusters=cv_k)
            
            if 'cross_validation_results' in st.session_state and st.session_state.cross_validation_results is not None:
                cv_results = st.session_state.cross_validation_results
                
                st.success(f"Ortalama SilÃ¼et Skoru: **{cv_results.get('avg_silhouette', 0):.4f}**")
                
                if 'fold_results' in cv_results:
                    st.write("#### ParÃ§a BazlÄ± SonuÃ§lar:")
                    st.table(pd.DataFrame(cv_results['fold_results']).set_index('fold'))
                
                if 'visualization' in cv_results:
                    show_matplotlib_figure(cv_results['visualization'])
        
        # Tab 6: PDF Raporu
        with tabs[5]:
            st.write("""
            ### PDF Raporu OluÅŸtur
            TÃ¼m analizleri iÃ§eren detaylÄ± bir PDF raporu oluÅŸturur.
            """)
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                report_title = st.text_input("Rapor BaÅŸlÄ±ÄŸÄ±", "SOM KÃ¼meleme Analizi Raporu")
                include_basic = st.checkbox("Temel Analizleri Dahil Et", True)
                include_advanced = st.checkbox("GeliÅŸmiÅŸ Analizleri Dahil Et", True)
            
            with col2:
                if st.button("PDF Rapor OluÅŸtur", key="create_pdf_button"):
                    try:
                        from pdf_report import create_pdf_report
                        
                        with st.spinner("PDF raporu oluÅŸturuluyor..."):
                            st.session_state.pdf_report = None  # Eski raporu temizle
                            
                            # GeliÅŸmiÅŸ analiz sonuÃ§larÄ±nÄ± birleÅŸtir
                            if include_advanced:
                                advanced_results = {}
                                
                                # Optimal K analizi
                                if 'optimal_k_results' in st.session_state and st.session_state.optimal_k_results is not None:
                                    advanced_results['optimal_k'] = st.session_state.optimal_k
                                    visualization = st.session_state.optimal_k_results.get('visualization')
                                    if visualization is not None:
                                        if isinstance(visualization, io.BytesIO):
                                            advanced_results['optimal_k_visualization'] = _buffer_to_base64(visualization)
                                        else:
                                            advanced_results['optimal_k_visualization'] = visualization
                                
                                # KÃ¼meleme algoritmalarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
                                if 'alternative_clustering_results' in st.session_state and st.session_state.alternative_clustering_results is not None:
                                    clustering_results = st.session_state.alternative_clustering_results
                                    visualizations = clustering_results.get('visualizations', {})
                                    
                                    # BytesIO nesnelerini base64'e Ã§evir
                                    converted_visualizations = {}
                                    for name, viz in visualizations.items():
                                        if viz is not None:
                                            if isinstance(viz, io.BytesIO):
                                                converted_visualizations[name] = _buffer_to_base64(viz)
                                            else:
                                                converted_visualizations[name] = viz
                                    
                                    advanced_results['clustering_comparison'] = {
                                        'metrics_df': clustering_results.get('metrics'),
                                        'visualizations': converted_visualizations
                                    }
                                
                                # Stabilite analizi
                                if 'stability_results' in st.session_state and st.session_state.stability_results is not None:
                                    stability_results = st.session_state.stability_results.copy()
                                    if 'visualization' in stability_results and stability_results['visualization'] is not None:
                                        if isinstance(stability_results['visualization'], io.BytesIO):
                                            stability_results['visualization'] = _buffer_to_base64(stability_results['visualization'])
                                    advanced_results['stability_analysis'] = stability_results
                                
                                # Boyut indirgeme
                                if 'dimensionality_reduction_results' in st.session_state and st.session_state.dimensionality_reduction_results is not None:
                                    dr_results = st.session_state.dimensionality_reduction_results
                                    converted_dr_results = {}
                                    for method_name, viz in dr_results.items():
                                        if viz is not None:
                                            if isinstance(viz, io.BytesIO):
                                                converted_dr_results[method_name] = _buffer_to_base64(viz)
                                            else:
                                                converted_dr_results[method_name] = viz
                                    
                                    advanced_results['dimensionality_reduction'] = {
                                        'visualizations': converted_dr_results
                                    }
                                
                                # Ã‡apraz doÄŸrulama
                                if 'cross_validation_results' in st.session_state and st.session_state.cross_validation_results is not None:
                                    cv_results = st.session_state.cross_validation_results
                                    cv_visualization = cv_results.get('visualization')
                                    if cv_visualization is not None and isinstance(cv_visualization, io.BytesIO):
                                        cv_visualization = _buffer_to_base64(cv_visualization)
                                    
                                    advanced_results['cross_validation'] = {
                                        'mean_silhouette': cv_results.get('avg_silhouette'),
                                        'std_silhouette': cv_results.get('std_silhouette', 0),
                                        'visualization': cv_visualization
                                    }
                                
                                # GeliÅŸmiÅŸ sonuÃ§larÄ± session state'e kaydet
                                st.session_state.advanced_analysis_results = advanced_results
                            
                            pdf_output = create_pdf_report(
                                title=report_title,
                                include_basic=include_basic,
                                include_advanced=include_advanced
                            )
                            
                            if pdf_output is not None:
                                st.session_state.pdf_report = pdf_output
                                st.success("PDF raporu baÅŸarÄ±yla oluÅŸturuldu!")
                            else:
                                st.error("PDF raporu oluÅŸturulurken bir hata oluÅŸtu.")
                    except Exception as e:
                        st.error(f"PDF rapor oluÅŸturma hatasÄ±: {str(e)}")
                        import traceback
                        st.write(traceback.format_exc())
                
            if 'pdf_report' in st.session_state and st.session_state.pdf_report is not None:
                st.download_button(
                    "PDF Raporunu Ä°ndir",
                    st.session_state.pdf_report,
                    "coraza_log_som_report.pdf",
                    "application/pdf"
                )
    
    except Exception as e:
        st.error(f"GeliÅŸmiÅŸ analiz sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}")
        import traceback
        st.write(traceback.format_exc())
